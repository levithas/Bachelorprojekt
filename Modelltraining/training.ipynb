{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:12:21.499677Z",
     "start_time": "2024-10-15T12:12:21.496939Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:15:47.252149Z",
     "start_time": "2024-10-15T12:15:47.247503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMConfig(BaseModel):\n",
    "    feature_columns: list[str]\n",
    "    label_column: str\n",
    "    scaled_labels: bool\n",
    "    n_steps: int = Field(default=50, ge=1)\n",
    "    batch_size: int = Field(default=32, ge=1)\n",
    "    epochs: int = Field(default=20, ge=1)\n",
    "    test_size: float = Field(default=0.2, ge=0, le=1)\n",
    "    checkpoint_path: str = Field(default=\"\")\n",
    "\n",
    "\n",
    "class TimeSeriesLSTM:\n",
    "\n",
    "    def __init__(self, config: LSTMConfig):\n",
    "        self.config = config\n",
    "        self.model: Model = None\n",
    "        self.build_model()\n",
    "\n",
    "    def preprocess_data(self, dataframe: pd.DataFrame, train_data=True):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(dataframe[self.config.feature_columns])\n",
    "        if train_data:\n",
    "            if self.config.scaled_labels:\n",
    "                labels = dataframe[self.config.label_column] / dataframe[self.config.label_column].max()\n",
    "            else:\n",
    "                labels = dataframe[self.config.label_column].values\n",
    "\n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled_data) - self.config.n_steps):\n",
    "            X.append(scaled_data[i:i + self.config.n_steps])\n",
    "            if train_data:\n",
    "                y.append(labels[i + self.config.n_steps])\n",
    "\n",
    "        if train_data:\n",
    "            return np.array(X), np.array(y)\n",
    "        return np.array(X)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "        print(\"Model loaded!\")\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Input((self.config.n_steps, len(self.config.feature_columns)), dtype=tf.float32, name='input_1'))\n",
    "        self.model.add(Dense(32, activation=\"relu\", dtype=tf.float32))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(LSTM(64, return_sequences=False, dtype=tf.float32))\n",
    "        self.model.add(Dense(1, activation=\"linear\", dtype=tf.float32))\n",
    "        self.model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    def train(self, dataframe: pd.DataFrame):\n",
    "        X, y = self.preprocess_data(dataframe)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.config.test_size, random_state=69)\n",
    "\n",
    "        self.model.fit(X_train, y_train, epochs=self.config.epochs, batch_size=self.config.batch_size)\n",
    "\n",
    "        loss = self.model.evaluate(X_test, y_test)\n",
    "        print(f\"Loss: {loss}\")\n",
    "\n",
    "    def predict(self, input_data: pd.DataFrame):\n",
    "        X = self.preprocess_data(input_data, train_data=False)\n",
    "        #X = X.reshape((1, self.config.n_steps, len(self.config.feature_columns)))\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "def generate_representative_data(data: pd.DataFrame, config: LSTMConfig):\n",
    "        X = []\n",
    "        \n",
    "        for i in range(len(data) - config.n_steps + 1):\n",
    "            X.append(data.iloc[i:i + config.n_steps].values)  # Hol dir die Zeitfenster\n",
    "        \n",
    "        X = np.array(X)\n",
    "\n",
    "        for sample in X:\n",
    "            sample = sample.reshape(1, config.n_steps, len(config.feature_columns))  # Form anpassen\n",
    "            yield {'input_1': sample}\n",
    "\n",
    "def convert_model_to_tflite(keras_path, tflite_path, representative_dataset, config: LSTMConfig): \n",
    "    print(\"Creating temp SavedModel!\")\n",
    "    keras_model = tf.keras.models.load_model(keras_path)\n",
    "    keras_model.export(\"tmp\")\n",
    "    \n",
    "    print(\"Converting SavedModel to tflite!\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=\"tmp\")\n",
    "    converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS , tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.inference_output_type = tf.float32\n",
    "\n",
    "    # Wird benötigt für den Quantizierungs-Prozess\n",
    "    converter.representative_dataset = lambda: generate_representative_data(representative_dataset, config)\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "        \n",
    "    print(\"Removing temp SavedModel!\")\n",
    "    shutil.rmtree(\"tmp\")\n",
    "    print(\"Finished!\")"
   ],
   "id": "d5da6b15ac1ab32f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Datensatz\n",
    "\n",
    "### Es wird ein zufälliger Datensatz erzeugt"
   ],
   "id": "cbb86afd06a2533d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:02:59.812687Z",
     "start_time": "2024-10-15T12:02:59.807707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zufällige Datensätze erzeugen\n",
    "train_dates = pd.date_range(start='2020-01-01', periods=10000)\n",
    "pred_dates = pd.date_range(start='2021-01-01', periods=100)\n",
    "\n",
    "train_data = {\n",
    "    'feature1': np.random.rand(10000).astype(np.float32),\n",
    "    'feature2': np.random.rand(10000).astype(np.float32),\n",
    "    'feature3': np.random.rand(10000).astype(np.float32),\n",
    "    'label': np.random.rand(10000).astype(np.float32)\n",
    "}\n",
    "\n",
    "pred_data = {\n",
    "    'feature1': np.random.rand(100).astype(np.float32),\n",
    "    'feature2': np.random.rand(100).astype(np.float32),\n",
    "    'feature3': np.random.rand(100).astype(np.float32),\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(train_data, index=train_dates)\n",
    "df_pred = pd.DataFrame(pred_data, index=pred_dates)"
   ],
   "id": "742904d59b89a4bc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Initialisierung\n",
    "\n",
    "### Das Model wird mit gegebener Konfiguration initialisiert"
   ],
   "id": "6561d11ae654ea5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:02:41.834852Z",
     "start_time": "2024-10-15T12:02:40.887350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konfiguration erstellen und Modell instanziieren\n",
    "config = LSTMConfig(\n",
    "    feature_columns=['feature1', 'feature2', 'feature3'],\n",
    "    label_column='label',\n",
    "    scaled_labels=False,\n",
    "    n_steps=25,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "f89d0ab3c6eb02d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728993761.772353   59162 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-15 14:02:41.772674: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trainings-Step",
   "id": "fc712c222bf5b4ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:16:58.065142Z",
     "start_time": "2024-10-15T12:16:50.240697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start des Trainings\n",
    "ts_lstm.train(dataframe=df_train)"
   ],
   "id": "34a68e059d933c63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0825\n",
      "Epoch 2/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0832\n",
      "Epoch 3/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0826\n",
      "Epoch 4/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0828\n",
      "Epoch 5/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0823\n",
      "Epoch 6/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0832\n",
      "Epoch 7/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0820\n",
      "Epoch 8/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0817\n",
      "Epoch 9/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0842\n",
      "Epoch 10/10\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.0827\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0828\n",
      "Loss: 0.08285371959209442\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prediction Step",
   "id": "80a043aa621074c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:13:31.300816Z",
     "start_time": "2024-10-15T12:13:31.104657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modell Predictions erzeugen\n",
    "\n",
    "pred_results = ts_lstm.predict(df_pred)\n",
    "\n",
    "df_pred_no_time = pd.DataFrame(pred_data)\n",
    "for index, row in df_pred_no_time.iterrows():\n",
    "    if index < config.n_steps:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", \"Not enough data\")\n",
    "    else:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", pred_results[index-config.n_steps])"
   ],
   "id": "c7d7dcacae7fea46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "F: 0.51403713 0.19882914 0.5911012  P: Not enough data\n",
      "F: 0.11934123 0.40530437 0.89096767  P: Not enough data\n",
      "F: 0.38564697 0.29791084 0.19773565  P: Not enough data\n",
      "F: 0.6703891 0.71410924 0.5589309  P: Not enough data\n",
      "F: 0.6856324 0.26695275 0.604667  P: Not enough data\n",
      "F: 0.37407333 0.5748829 0.76460654  P: Not enough data\n",
      "F: 0.045838956 0.85503596 0.37089372  P: Not enough data\n",
      "F: 0.11443184 0.062243324 0.710078  P: Not enough data\n",
      "F: 0.35948795 0.42584494 0.7620492  P: Not enough data\n",
      "F: 0.5214783 0.36130518 0.88608074  P: Not enough data\n",
      "F: 0.9309409 0.4325166 0.7721853  P: Not enough data\n",
      "F: 0.5279233 0.8800477 0.5392751  P: Not enough data\n",
      "F: 0.33663088 0.6341414 0.3659117  P: Not enough data\n",
      "F: 0.8563349 0.4537363 0.38099846  P: Not enough data\n",
      "F: 0.7088956 0.10979994 0.4552031  P: Not enough data\n",
      "F: 0.42051426 0.9532006 0.94734293  P: Not enough data\n",
      "F: 0.62419176 0.5616601 0.22580338  P: Not enough data\n",
      "F: 0.19315931 0.49989152 0.94404525  P: Not enough data\n",
      "F: 0.13220085 0.38574183 0.85863066  P: Not enough data\n",
      "F: 0.48927695 0.560172 0.011551256  P: Not enough data\n",
      "F: 0.10607543 0.7570634 0.8861291  P: Not enough data\n",
      "F: 0.6636275 0.32873437 0.823422  P: Not enough data\n",
      "F: 0.08417101 0.9938953 0.8140583  P: Not enough data\n",
      "F: 0.7712223 0.6914217 0.5376309  P: Not enough data\n",
      "F: 0.28833458 0.406496 0.1978169  P: Not enough data\n",
      "F: 0.3983846 0.95207506 0.7505153  P: [0.4747945]\n",
      "F: 0.3946925 0.8963494 0.3028491  P: [0.47674352]\n",
      "F: 0.05294987 0.28149277 0.39824852  P: [0.4765578]\n",
      "F: 0.32014358 0.67472327 0.7792752  P: [0.47411436]\n",
      "F: 0.6616065 0.05735944 0.5675902  P: [0.47449017]\n",
      "F: 0.63627666 0.56664836 0.048654612  P: [0.48015147]\n",
      "F: 0.7836055 0.27310893 0.54620373  P: [0.48141724]\n",
      "F: 0.6484505 0.09207389 0.8531832  P: [0.48441964]\n",
      "F: 0.08989168 0.44443265 0.8396912  P: [0.48345304]\n",
      "F: 0.23692825 0.14912888 0.705546  P: [0.47215357]\n",
      "F: 0.25583413 0.16654022 0.43946144  P: [0.4717213]\n",
      "F: 0.90758824 0.054478835 0.55237436  P: [0.472692]\n",
      "F: 0.54202956 0.34710947 0.7996528  P: [0.4859445]\n",
      "F: 0.8535665 0.30902532 0.61588776  P: [0.47387305]\n",
      "F: 0.13289605 0.4401018 0.5260575  P: [0.48000765]\n",
      "F: 0.4949505 0.40676832 0.98499477  P: [0.47138277]\n",
      "F: 0.5682406 0.32822976 0.65451807  P: [0.47098333]\n",
      "F: 0.06937735 0.44287038 0.003226418  P: [0.47277576]\n",
      "F: 0.9737601 0.61246467 0.6494063  P: [0.4554853]\n",
      "F: 0.4491022 0.53566504 0.36772522  P: [0.4763246]\n",
      "F: 0.9589011 0.16532339 0.25872746  P: [0.47488588]\n",
      "F: 0.35778314 0.53696716 0.47385022  P: [0.48181242]\n",
      "F: 0.7914795 0.32677048 0.029292451  P: [0.47396198]\n",
      "F: 0.35182625 0.571196 0.27259728  P: [0.47975123]\n",
      "F: 0.65045106 0.5139587 0.87588966  P: [0.4820324]\n",
      "F: 0.23736574 0.19045915 0.10954196  P: [0.47940883]\n",
      "F: 0.26739395 0.011894234 0.9883093  P: [0.4783193]\n",
      "F: 0.6599377 0.07068916 0.8319202  P: [0.49350882]\n",
      "F: 0.28839165 0.8456586 0.6589199  P: [0.49697053]\n",
      "F: 0.3723383 0.60607576 0.69709474  P: [0.48417118]\n",
      "F: 0.96213895 0.66323584 0.39301363  P: [0.47717944]\n",
      "F: 0.97018456 0.52318275 0.12182373  P: [0.48492488]\n",
      "F: 0.6433087 0.7741509 0.5152273  P: [0.4877857]\n",
      "F: 0.5384767 0.08750506 0.22002523  P: [0.48532793]\n",
      "F: 0.8372823 0.37949324 0.72962517  P: [0.48379055]\n",
      "F: 0.8990525 0.22580017 0.18464856  P: [0.48306602]\n",
      "F: 0.38456175 0.42463702 0.82179976  P: [0.48359343]\n",
      "F: 0.22523522 0.33518478 0.3476741  P: [0.47506094]\n",
      "F: 0.27739954 0.22606632 0.6430577  P: [0.47542217]\n",
      "F: 0.53853005 0.11766241 0.062447235  P: [0.4764195]\n",
      "F: 0.8546604 0.32708746 0.31126377  P: [0.4810237]\n",
      "F: 0.8320798 0.5203937 0.23040089  P: [0.48700133]\n",
      "F: 0.7700596 0.37310278 0.22462413  P: [0.4888732]\n",
      "F: 0.8811286 0.33805534 0.3160066  P: [0.49077147]\n",
      "F: 0.39301956 0.94850457 0.78877866  P: [0.49121043]\n",
      "F: 0.9404266 0.2587561 0.7262606  P: [0.4834284]\n",
      "F: 0.86999303 0.16029647 0.9210936  P: [0.4847135]\n",
      "F: 0.95227265 0.8303039 0.57670903  P: [0.48483428]\n",
      "F: 0.90284497 0.55347264 0.037326545  P: [0.47911057]\n",
      "F: 0.009861089 0.09669762 0.56428945  P: [0.48392802]\n",
      "F: 0.1313332 0.5159357 0.18208331  P: [0.49755904]\n",
      "F: 0.98926836 0.866441 0.27117586  P: [0.48962212]\n",
      "F: 0.54463947 0.687957 0.46692324  P: [0.49957368]\n",
      "F: 0.33682856 0.118074484 0.91983795  P: [0.49695292]\n",
      "F: 0.3379626 0.06699804 0.35189778  P: [0.4903919]\n",
      "F: 0.102978736 0.20571272 0.7865161  P: [0.48796052]\n",
      "F: 0.036181226 0.2901685 0.8909183  P: [0.49159068]\n",
      "F: 0.13929659 0.38210917 0.20137511  P: [0.49886402]\n",
      "F: 0.6124165 0.46874627 0.69383776  P: [0.4895938]\n",
      "F: 0.16323213 0.8740749 0.5594947  P: [0.48631874]\n",
      "F: 0.66703963 0.66398436 0.7964448  P: [0.4803588]\n",
      "F: 0.5614926 0.9724125 0.02677405  P: [0.47407672]\n",
      "F: 0.2485148 0.4724953 0.4603526  P: [0.4737911]\n",
      "F: 0.67865247 0.60557866 0.13872944  P: [0.47456843]\n",
      "F: 0.79949206 0.414929 0.6851424  P: [0.4815458]\n",
      "F: 0.11192233 0.77361333 0.521974  P: [0.48248243]\n",
      "F: 0.8939152 0.5715325 0.108909816  P: [0.47286963]\n",
      "F: 0.39729017 0.73760843 0.35122886  P: [0.47731414]\n",
      "F: 0.5152495 0.06440042 0.17496228  P: [0.4808576]\n",
      "F: 0.53784806 0.47035545 0.9190049  P: [0.47928366]\n",
      "F: 0.27196544 0.09998814 0.23230983  P: [0.47511142]\n",
      "F: 0.37764835 0.9940766 0.46451226  P: [0.4732932]\n",
      "F: 0.44830796 0.6026568 0.09229851  P: [0.47669733]\n",
      "F: 0.36787257 0.8829762 0.49822736  P: [0.4812325]\n",
      "F: 0.8515667 0.2094194 0.81918967  P: [0.48210216]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modell Speichern, Laden und Konvertieren",
   "id": "62f4cc1909cebe6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:17:13.134800Z",
     "start_time": "2024-10-15T12:17:13.121249Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.save_model(\"TestModel.keras\")",
   "id": "209c16dc220efd3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:16:18.382574Z",
     "start_time": "2024-10-15T12:16:18.340959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lade das Modell aus der TF-Lite Datei\n",
    "ts_lstm.load_model(\"TestModel.keras\")"
   ],
   "id": "4830dba6364866cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:17:15.708269Z",
     "start_time": "2024-10-15T12:17:15.224955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konvertiere das Keras-Modell in ein tflite-Modell\n",
    "convert_model_to_tflite(\"TestModel.keras\", \"TestModel.tflite\", df_pred, config)"
   ],
   "id": "c5bcafd41e5d9483",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temp SavedModel!\n",
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'tmp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 25, 3), dtype=tf.float32, name='input_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  133969986470656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133969986481920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133969987150848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133969987152256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133969987154016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133969986472064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133970011606528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Converting SavedModel to tflite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728994635.508054   59162 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1728994635.508067   59162 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-10-15 14:17:15.508205: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: tmp\n",
      "2024-10-15 14:17:15.508665: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-15 14:17:15.508674: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: tmp\n",
      "2024-10-15 14:17:15.513278: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-15 14:17:15.537195: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: tmp\n",
      "2024-10-15 14:17:15.545987: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 37784 microseconds.\n",
      "2024-10-15 14:17:15.589835: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3463] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<1x?x64xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "I0000 00:00:1728994635.592216   59162 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-15 14:17:15.592357: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-10-15 14:17:15.592762: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_inter_op_parallelism which is not in the op definition: Op<name=TensorListReserve; signature=element_shape:shape_type, num_elements:int32 -> handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node TensorListReserve}}\n",
      "I0000 00:00:1728994635.594895   59162 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-15 14:17:15.595009: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp SavedModel!\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:03:19.899068Z",
     "start_time": "2024-10-10T14:02:29.213983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "feature_columns = [\n",
    "    \"movementData\",\n",
    "    #\"sleepLevels\",\n",
    "    #\"restlessMoments\",\n",
    "    \"heartrate\",\n",
    "    #\"stress\",\n",
    "    #\"bodyBattery\",\n",
    "    #\"hrv\"\n",
    "]\n",
    "\n",
    "label_column = 'sleepLevels'\n",
    "\n",
    "config = LSTMConfig(\n",
    "    feature_columns=feature_columns,\n",
    "    label_column=label_column,\n",
    "    n_steps=50,\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    scaled_labels=True,\n",
    "    checkpoint_path=\"models/chkp.keras\")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)\n",
    "ts_lstm.train(dataframe=df_train[feature_columns + [label_column]])\n",
    "\n",
    "inputs = np.ones((1,50,2)) * 0.1\n",
    "\n",
    "print(\"Inputs:\", inputs, \"|\", \"Output:\", ts_lstm.predict(inputs))\n",
    "\n",
    "ts_lstm.save_tflite_model(\"models/tfLiteModel.tflite\", dataset=df_train[feature_columns])"
   ],
   "id": "df452a55c88e3f04",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21587/2948458530.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21587/2818307351.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y.append(labels[i + self.config.n_steps])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m743/744\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0316\n",
      "Epoch 1: saving model to models/chkp.keras\n",
      "\u001B[1m744/744\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 7ms/step - loss: 0.0316\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 0.0262\n",
      "Loss: 0.026939673349261284\n",
      "INFO:tensorflow:Assets written to: testModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'testModel/'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 2), dtype=tf.float32, name='input_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 50, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  130926510587072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926510587248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926510582496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926511002848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926511003728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728568957.471736   21587 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1728568957.471755   21587 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-10-10 16:02:37.471911: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: testModel/\n",
      "2024-10-10 16:02:37.472380: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-10 16:02:37.472390: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: testModel/\n",
      "2024-10-10 16:02:37.476396: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-10 16:02:37.495943: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: testModel/\n",
      "2024-10-10 16:02:37.503940: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 32032 microseconds.\n",
      "2024-10-10 16:02:37.542021: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3463] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x50xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x50xf32>>>, tensor<i32>, tensor<?x50xf32>) -> (tensor<!tf_type.variant<tensor<?x50xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x50xf32>>>, tensor<2xi32>) -> (tensor<50x?x50xf32>) : {device = \"\", num_elements = 50 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "I0000 00:00:1728568957.545027   21587 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-10 16:02:37.545189: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-10-10 16:02:37.545632: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_inter_op_parallelism which is not in the op definition: Op<name=TensorListReserve; signature=element_shape:shape_type, num_elements:int32 -> handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node TensorListReserve}}\n",
      "I0000 00:00:1728568957.993692   21587 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-10 16:02:37.993866: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utils",
   "id": "ee35f19675a17710"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def list_all_files(path):\n",
    "    try:\n",
    "        files = []\n",
    "\n",
    "        for f in os.listdir(path):\n",
    "            filepath = os.path.join(path, f)\n",
    "            if os.path.isfile(filepath):  # Prüft, ob es sich um eine Datei handelt\n",
    "                files.append(f)\n",
    "\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Das Verzeichnis '{path}' wurde nicht gefunden.\")\n",
    "        return []"
   ],
   "id": "5f712c5337735a19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
