{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T12:57:42.169776Z",
     "start_time": "2025-01-13T12:57:40.293271Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import flatbuffers\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Concatenate, Normalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support import metadata as _metadata"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 13:57:40.758469: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-13 13:57:40.760031: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-13 13:57:40.791870: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-13 13:57:40.792436: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-13 13:57:41.290029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:45:51.064896Z",
     "start_time": "2025-01-13T13:45:51.049796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMConfig(BaseModel):\n",
    "    feature_columns: list[str]\n",
    "    label_names: list[str]\n",
    "    label_count: int = Field(default=0)\n",
    "    scaled_labels: bool\n",
    "    n_steps: int = Field(default=50, ge=1)\n",
    "    batch_size: int = Field(default=32, ge=1)\n",
    "    epochs: int = Field(default=20, ge=1)\n",
    "    test_size: float = Field(default=0.2, ge=0, le=1)\n",
    "    checkpoint_path: str = Field(default=\"\")\n",
    "    loss_function: str\n",
    "\n",
    "\n",
    "class TimeSeriesLSTM:\n",
    "\n",
    "    def __init__(self, config: LSTMConfig):\n",
    "        self.config = config\n",
    "        self.model: Model = None\n",
    "\n",
    "    def _create_segments(self, data: pd.Series, n_steps):\n",
    "        num_samples = len(data) - n_steps + 1\n",
    "        return np.array([data[i:i + n_steps] for i in range(num_samples)]).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    def dataframe_to_pred_data(self, df_prediction: pd.DataFrame):\n",
    "        features = self.config.feature_columns\n",
    "        n_steps = self.config.n_steps\n",
    "        \n",
    "        X = []\n",
    "        # Create Time Sin...\n",
    "        segmented_data = self._create_segments(np.sin(df_prediction.index.asi8 / (3600*24)), n_steps)\n",
    "        X.append(segmented_data[:, :, np.newaxis])\n",
    "        \n",
    "        # ...and Cos from Timestamp\n",
    "        segmented_data = self._create_segments(np.cos(df_prediction.index.asi8 / (3600*24)), n_steps)\n",
    "        X.append(segmented_data[:, :, np.newaxis])\n",
    "        \n",
    "        for feature in features:\n",
    "            segmented_data = self._create_segments(df_prediction[feature], n_steps)\n",
    "            X.append(segmented_data[:, :, np.newaxis])\n",
    "        \n",
    "        return np.concatenate(X, axis=2)\n",
    "    \n",
    "\n",
    "    def dataframe_to_train_data(self, df_training: pd.DataFrame):\n",
    "        features = self.config.feature_columns\n",
    "        labels = self.config.label_names\n",
    "        n_steps = self.config.n_steps\n",
    "        \n",
    "        X = self.dataframe_to_pred_data(df_training[features])\n",
    "        \n",
    "        label_arrays = [self._create_segments(df_training[label], n_steps)[:, -1] for label in labels]\n",
    "        y = np.stack(label_arrays, axis=1)\n",
    "        \n",
    "        print(f\"Shape of X: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape}\")\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "        print(\"Model loaded!\")\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "    def build_model(self, adaptation_data):\n",
    "        inputs = []\n",
    "        lstm_outputs = []\n",
    "        feature_list = [\"time_sin\", \"time_cos\"] + self.config.feature_columns\n",
    "        \n",
    "        for feature_idx in range(len(feature_list)):            \n",
    "            input_tensor = Input(shape=(self.config.n_steps, 1), dtype=tf.float32, name=f'input_{feature_list[feature_idx]}')\n",
    "            inputs.append(input_tensor)\n",
    "            normalization = Normalization()\n",
    "            normalization.adapt(adaptation_data.iloc[feature_idx])\n",
    "            lstm = LSTM(64, return_sequences=False, dtype=tf.float32)\n",
    "            lstm_outputs.append(lstm(normalization(input_tensor)))\n",
    "\n",
    "        merged = Concatenate(axis=1)(lstm_outputs)\n",
    "        \n",
    "        x = Dense(64, activation='relu')(merged)\n",
    "        if len(self.config.label_names) == 1:\n",
    "            output = Dense(self.config.label_count, activation='softmax')(x)\n",
    "        else:\n",
    "            output = Dense(len(self.config.label_names), activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=inputs, outputs=output)\n",
    "        self.model.compile(optimizer=Adam(), loss=self.config.loss_function, metrics=['accuracy'])\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def train(self, dataframe: pd.DataFrame):\n",
    "        X, y = self.dataframe_to_train_data(dataframe)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.config.test_size, random_state=69)\n",
    "        \n",
    "        X_train_split = np.split(X_train, indices_or_sections=len(self.config.feature_columns)+2, axis=2)\n",
    "        X_test_split = np.split(X_test, indices_or_sections=len(self.config.feature_columns)+2, axis=2)\n",
    "\n",
    "        X_train_squeeze = [arr.squeeze(axis=2) for arr in X_train_split]\n",
    "        X_test_squeeze = [arr.squeeze(axis=2) for arr in X_test_split]\n",
    "\n",
    "        self.model.fit(X_train_squeeze, y_train, epochs=self.config.epochs, batch_size=self.config.batch_size)\n",
    "        loss = self.model.evaluate(X_test_squeeze, y_test)\n",
    "        \n",
    "        print(f\"Loss: {loss}\")\n",
    "\n",
    "    def predict(self, input_data: pd.DataFrame):\n",
    "        X = self.dataframe_to_pred_data(input_data)       \n",
    "        X_split = np.split(X, indices_or_sections=len(self.config.feature_columns)+2, axis=2)\n",
    "        X_squeeze = [arr.squeeze(axis=2) for arr in X_split]\n",
    "        return self.model.predict(X_squeeze)\n",
    "\n",
    "    def convert_to_tflite(self, tflite_path, representative_dataset):\n",
    "        print(\"Creating temp SavedModel\")\n",
    "        self.model.export(\"tmp\")\n",
    "        \n",
    "        print(\"Converting SavedModel to tflite\")\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=\"tmp\")\n",
    "        converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS , tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "        converter.inference_input_type = tf.float32\n",
    "        converter.inference_output_type = tf.float32\n",
    "        \n",
    "        # def representative_data_generator():\n",
    "        #     X = self.dataframe_to_pred_data(representative_dataset)\n",
    "        #     \n",
    "        #     for i, sample in enumerate(X):\n",
    "        #         sample = sample.reshape(1, self.config.n_steps, len(self.config.feature_columns)+2)\n",
    "        #         if i == 0:\n",
    "        #             name = \"time\"\n",
    "        #         else:\n",
    "        #             name = self.config.feature_columns[i-1]\n",
    "        #         yield {f'input_{name}': sample}\n",
    "        \n",
    "        def representative_data_generatorV2():\n",
    "            X = self.dataframe_to_pred_data(representative_dataset)\n",
    "            feature_count = len(self.config.feature_columns)+2\n",
    "            \n",
    "            for i, sample in enumerate(X):\n",
    "                reshaped_sample = sample.reshape(1, self.config.n_steps, feature_count)\n",
    "                sample_list = np.split(reshaped_sample, indices_or_sections=feature_count, axis=2)\n",
    "                yield sample_list\n",
    "        \n",
    "        converter.representative_dataset = lambda: representative_data_generatorV2()\n",
    "        \n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "            \n",
    "        print(\"Removing temp SavedModel\")\n",
    "        shutil.rmtree(\"tmp\")\n",
    "        print(\"Finished!\")\n"
   ],
   "id": "d5da6b15ac1ab32f",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "639bc7eda3696212"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Datensatz\n",
    "\n",
    "### Es wird ein zufälliger Datensatz erzeugt"
   ],
   "id": "cbb86afd06a2533d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:21:15.636747Z",
     "start_time": "2024-12-20T12:21:15.627849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zufällige Datensätze erzeugen\n",
    "train_dates = pd.date_range(start='2020-01-01', periods=10000)\n",
    "pred_dates = pd.date_range(start='2021-01-01', periods=100)\n",
    "\n",
    "train_labels = np.random.randint(low=0, high=3, size=10000)\n",
    "\n",
    "train_data = {\n",
    "    'feature1': np.random.rand(10000).astype(np.float32),\n",
    "    'feature2': np.random.rand(10000).astype(np.float32),\n",
    "    'feature3': np.random.rand(10000).astype(np.float32),\n",
    "    'sleep': np.array([1 if lb == 0 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'awake': np.array([1 if lb == 1 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'rem': np.array([1 if lb == 2 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'light': np.array([1 if lb == 3 else 0 for lb in train_labels]).astype(np.float32)\n",
    "}\n",
    "\n",
    "pred_data = {\n",
    "    'feature1': np.random.rand(100).astype(np.float32),\n",
    "    'feature2': np.random.rand(100).astype(np.float32),\n",
    "    'feature3': np.random.rand(100).astype(np.float32),\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(train_data, index=train_dates)\n",
    "df_pred = pd.DataFrame(pred_data, index=pred_dates)"
   ],
   "id": "742904d59b89a4bc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Initialisierung\n",
    "\n",
    "### Das Model wird mit gegebener Konfiguration initialisiert"
   ],
   "id": "6561d11ae654ea5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:25:45.766856Z",
     "start_time": "2025-01-10T13:25:45.166190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konfiguration erstellen und Modell instanziieren\n",
    "config = LSTMConfig(\n",
    "    feature_columns=['time', 'movement', 'heartrate'],\n",
    "    label_names=['awake','lightSleep', 'asleep',  'REM'],\n",
    "    scaled_labels=False,\n",
    "    n_steps=25,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    loss_function=\"categorical_crossentropy\"\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "f89d0ab3c6eb02d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 14:25:45.335999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_time (InputLayer)     [(None, 25, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " input_movement (InputLayer  [(None, 25, 1)]              0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_heartrate (InputLaye  [(None, 25, 1)]              0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 64)                   16896     ['input_time[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 64)                   16896     ['input_movement[0][0]']      \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 64)                   16896     ['input_heartrate[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 192)                  0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   12352     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    65        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63105 (246.50 KB)\n",
      "Trainable params: 63105 (246.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trainings-Step",
   "id": "fc712c222bf5b4ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:23:50.504600Z",
     "start_time": "2024-12-20T12:23:19.266398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start des Trainings\n",
    "ts_lstm.train(dataframe=df_train)"
   ],
   "id": "34a68e059d933c63",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTMConfig' object has no attribute 'label_column'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Start des Trainings\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mts_lstm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[24], line 65\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.train\u001B[0;34m(self, dataframe)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataframe: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[0;32m---> 65\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m     X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtest_size, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m69\u001B[39m)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mepochs, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size)\n",
      "Cell \u001B[0;32mIn[24], line 26\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.preprocess_data\u001B[0;34m(self, dataframe, train_data)\u001B[0m\n\u001B[1;32m     24\u001B[0m         labels \u001B[38;5;241m=\u001B[39m dataframe[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlabel_column] \u001B[38;5;241m/\u001B[39m dataframe[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlabel_column]\u001B[38;5;241m.\u001B[39mmax()\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 26\u001B[0m         labels \u001B[38;5;241m=\u001B[39m dataframe[\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_column\u001B[49m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     28\u001B[0m X, y \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(scaled_data) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mn_steps):\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/pydantic/main.py:856\u001B[0m, in \u001B[0;36mBaseModel.__getattr__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(item)  \u001B[38;5;66;03m# Raises AttributeError if appropriate\u001B[39;00m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[0;32m--> 856\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LSTMConfig' object has no attribute 'label_column'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prediction Step",
   "id": "80a043aa621074c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:13:31.300816Z",
     "start_time": "2024-10-15T12:13:31.104657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modell Predictions erzeugen\n",
    "\n",
    "pred_results = ts_lstm.predict(df_pred)\n",
    "\n",
    "df_pred_no_time = pd.DataFrame(pred_data)\n",
    "for index, row in df_pred_no_time.iterrows():\n",
    "    if index < config.n_steps:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", \"Not enough data\")\n",
    "    else:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", pred_results[index-config.n_steps])"
   ],
   "id": "c7d7dcacae7fea46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "F: 0.51403713 0.19882914 0.5911012  P: Not enough data\n",
      "F: 0.11934123 0.40530437 0.89096767  P: Not enough data\n",
      "F: 0.38564697 0.29791084 0.19773565  P: Not enough data\n",
      "F: 0.6703891 0.71410924 0.5589309  P: Not enough data\n",
      "F: 0.6856324 0.26695275 0.604667  P: Not enough data\n",
      "F: 0.37407333 0.5748829 0.76460654  P: Not enough data\n",
      "F: 0.045838956 0.85503596 0.37089372  P: Not enough data\n",
      "F: 0.11443184 0.062243324 0.710078  P: Not enough data\n",
      "F: 0.35948795 0.42584494 0.7620492  P: Not enough data\n",
      "F: 0.5214783 0.36130518 0.88608074  P: Not enough data\n",
      "F: 0.9309409 0.4325166 0.7721853  P: Not enough data\n",
      "F: 0.5279233 0.8800477 0.5392751  P: Not enough data\n",
      "F: 0.33663088 0.6341414 0.3659117  P: Not enough data\n",
      "F: 0.8563349 0.4537363 0.38099846  P: Not enough data\n",
      "F: 0.7088956 0.10979994 0.4552031  P: Not enough data\n",
      "F: 0.42051426 0.9532006 0.94734293  P: Not enough data\n",
      "F: 0.62419176 0.5616601 0.22580338  P: Not enough data\n",
      "F: 0.19315931 0.49989152 0.94404525  P: Not enough data\n",
      "F: 0.13220085 0.38574183 0.85863066  P: Not enough data\n",
      "F: 0.48927695 0.560172 0.011551256  P: Not enough data\n",
      "F: 0.10607543 0.7570634 0.8861291  P: Not enough data\n",
      "F: 0.6636275 0.32873437 0.823422  P: Not enough data\n",
      "F: 0.08417101 0.9938953 0.8140583  P: Not enough data\n",
      "F: 0.7712223 0.6914217 0.5376309  P: Not enough data\n",
      "F: 0.28833458 0.406496 0.1978169  P: Not enough data\n",
      "F: 0.3983846 0.95207506 0.7505153  P: [0.4747945]\n",
      "F: 0.3946925 0.8963494 0.3028491  P: [0.47674352]\n",
      "F: 0.05294987 0.28149277 0.39824852  P: [0.4765578]\n",
      "F: 0.32014358 0.67472327 0.7792752  P: [0.47411436]\n",
      "F: 0.6616065 0.05735944 0.5675902  P: [0.47449017]\n",
      "F: 0.63627666 0.56664836 0.048654612  P: [0.48015147]\n",
      "F: 0.7836055 0.27310893 0.54620373  P: [0.48141724]\n",
      "F: 0.6484505 0.09207389 0.8531832  P: [0.48441964]\n",
      "F: 0.08989168 0.44443265 0.8396912  P: [0.48345304]\n",
      "F: 0.23692825 0.14912888 0.705546  P: [0.47215357]\n",
      "F: 0.25583413 0.16654022 0.43946144  P: [0.4717213]\n",
      "F: 0.90758824 0.054478835 0.55237436  P: [0.472692]\n",
      "F: 0.54202956 0.34710947 0.7996528  P: [0.4859445]\n",
      "F: 0.8535665 0.30902532 0.61588776  P: [0.47387305]\n",
      "F: 0.13289605 0.4401018 0.5260575  P: [0.48000765]\n",
      "F: 0.4949505 0.40676832 0.98499477  P: [0.47138277]\n",
      "F: 0.5682406 0.32822976 0.65451807  P: [0.47098333]\n",
      "F: 0.06937735 0.44287038 0.003226418  P: [0.47277576]\n",
      "F: 0.9737601 0.61246467 0.6494063  P: [0.4554853]\n",
      "F: 0.4491022 0.53566504 0.36772522  P: [0.4763246]\n",
      "F: 0.9589011 0.16532339 0.25872746  P: [0.47488588]\n",
      "F: 0.35778314 0.53696716 0.47385022  P: [0.48181242]\n",
      "F: 0.7914795 0.32677048 0.029292451  P: [0.47396198]\n",
      "F: 0.35182625 0.571196 0.27259728  P: [0.47975123]\n",
      "F: 0.65045106 0.5139587 0.87588966  P: [0.4820324]\n",
      "F: 0.23736574 0.19045915 0.10954196  P: [0.47940883]\n",
      "F: 0.26739395 0.011894234 0.9883093  P: [0.4783193]\n",
      "F: 0.6599377 0.07068916 0.8319202  P: [0.49350882]\n",
      "F: 0.28839165 0.8456586 0.6589199  P: [0.49697053]\n",
      "F: 0.3723383 0.60607576 0.69709474  P: [0.48417118]\n",
      "F: 0.96213895 0.66323584 0.39301363  P: [0.47717944]\n",
      "F: 0.97018456 0.52318275 0.12182373  P: [0.48492488]\n",
      "F: 0.6433087 0.7741509 0.5152273  P: [0.4877857]\n",
      "F: 0.5384767 0.08750506 0.22002523  P: [0.48532793]\n",
      "F: 0.8372823 0.37949324 0.72962517  P: [0.48379055]\n",
      "F: 0.8990525 0.22580017 0.18464856  P: [0.48306602]\n",
      "F: 0.38456175 0.42463702 0.82179976  P: [0.48359343]\n",
      "F: 0.22523522 0.33518478 0.3476741  P: [0.47506094]\n",
      "F: 0.27739954 0.22606632 0.6430577  P: [0.47542217]\n",
      "F: 0.53853005 0.11766241 0.062447235  P: [0.4764195]\n",
      "F: 0.8546604 0.32708746 0.31126377  P: [0.4810237]\n",
      "F: 0.8320798 0.5203937 0.23040089  P: [0.48700133]\n",
      "F: 0.7700596 0.37310278 0.22462413  P: [0.4888732]\n",
      "F: 0.8811286 0.33805534 0.3160066  P: [0.49077147]\n",
      "F: 0.39301956 0.94850457 0.78877866  P: [0.49121043]\n",
      "F: 0.9404266 0.2587561 0.7262606  P: [0.4834284]\n",
      "F: 0.86999303 0.16029647 0.9210936  P: [0.4847135]\n",
      "F: 0.95227265 0.8303039 0.57670903  P: [0.48483428]\n",
      "F: 0.90284497 0.55347264 0.037326545  P: [0.47911057]\n",
      "F: 0.009861089 0.09669762 0.56428945  P: [0.48392802]\n",
      "F: 0.1313332 0.5159357 0.18208331  P: [0.49755904]\n",
      "F: 0.98926836 0.866441 0.27117586  P: [0.48962212]\n",
      "F: 0.54463947 0.687957 0.46692324  P: [0.49957368]\n",
      "F: 0.33682856 0.118074484 0.91983795  P: [0.49695292]\n",
      "F: 0.3379626 0.06699804 0.35189778  P: [0.4903919]\n",
      "F: 0.102978736 0.20571272 0.7865161  P: [0.48796052]\n",
      "F: 0.036181226 0.2901685 0.8909183  P: [0.49159068]\n",
      "F: 0.13929659 0.38210917 0.20137511  P: [0.49886402]\n",
      "F: 0.6124165 0.46874627 0.69383776  P: [0.4895938]\n",
      "F: 0.16323213 0.8740749 0.5594947  P: [0.48631874]\n",
      "F: 0.66703963 0.66398436 0.7964448  P: [0.4803588]\n",
      "F: 0.5614926 0.9724125 0.02677405  P: [0.47407672]\n",
      "F: 0.2485148 0.4724953 0.4603526  P: [0.4737911]\n",
      "F: 0.67865247 0.60557866 0.13872944  P: [0.47456843]\n",
      "F: 0.79949206 0.414929 0.6851424  P: [0.4815458]\n",
      "F: 0.11192233 0.77361333 0.521974  P: [0.48248243]\n",
      "F: 0.8939152 0.5715325 0.108909816  P: [0.47286963]\n",
      "F: 0.39729017 0.73760843 0.35122886  P: [0.47731414]\n",
      "F: 0.5152495 0.06440042 0.17496228  P: [0.4808576]\n",
      "F: 0.53784806 0.47035545 0.9190049  P: [0.47928366]\n",
      "F: 0.27196544 0.09998814 0.23230983  P: [0.47511142]\n",
      "F: 0.37764835 0.9940766 0.46451226  P: [0.4732932]\n",
      "F: 0.44830796 0.6026568 0.09229851  P: [0.47669733]\n",
      "F: 0.36787257 0.8829762 0.49822736  P: [0.4812325]\n",
      "F: 0.8515667 0.2094194 0.81918967  P: [0.48210216]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modell Speichern, Laden und Konvertieren",
   "id": "62f4cc1909cebe6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:20:35.348596Z",
     "start_time": "2024-12-17T17:20:35.320025Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.save_model(\"TestModel.keras\")",
   "id": "209c16dc220efd3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:33:31.855675Z",
     "start_time": "2024-12-17T17:33:31.697605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lade das Modell aus der TF-Lite Datei\n",
    "ts_lstm.load_model(\"TestModel.keras\")"
   ],
   "id": "4830dba6364866cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:59:12.689065Z",
     "start_time": "2025-01-13T13:59:12.602677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ModelSpecificInfo(BaseModel):\n",
    "    name: str\n",
    "    version: float\n",
    "    num_inputs: int\n",
    "    num_outputs: int        \n",
    "\n",
    "\n",
    "_MODEL_INFO = ModelSpecificInfo(\n",
    "        name=\"Schlafphasenmodell\",\n",
    "        version=0.1,\n",
    "        num_inputs=4,\n",
    "        num_outputs=1\n",
    ")\n",
    "\n",
    "\n",
    "def add_metadata_to_model(model_path: str, metadata: ModelSpecificInfo):\n",
    "    \n",
    "    model_meta = _metadata_fb.ModelMetadataT()\n",
    "    model_meta.name = metadata.name\n",
    "    model_meta.description = \"Ein Schlafphasenanalyse-Modell\"\n",
    "    \n",
    "    input_meta_0 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_0.name = \"Time Sinus\"\n",
    "    input_meta_0.dimensionNames = ['sin']\n",
    "    input_meta_0.description = \"Die Tageszeit an dem der Wert aufgenommen wurde als Sinus codiert\"\n",
    "    input_meta_0.content = _metadata_fb.ContentT()\n",
    "    input_meta_0.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_0.content.contentProperties.min = -1\n",
    "    input_meta_0.content.contentProperties.max = 1\n",
    "    \n",
    "    input_meta_1 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_1.name = \"Time Cosinus\"\n",
    "    input_meta_1.dimensionNames = ['cos']\n",
    "    input_meta_1.description = \"Die Tageszeit an dem der Wert aufgenommen wurde als Cosinus codiert\"\n",
    "    input_meta_1.content = _metadata_fb.ContentT()\n",
    "    input_meta_1.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_1.content.contentProperties.min = -1\n",
    "    input_meta_1.content.contentProperties.max = 1\n",
    "    \n",
    "    input_meta_2 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_2.name = \"Movement\"\n",
    "    input_meta_2.description = \"Die Bewegungsintensität gemittelt aus den Beschleunigungssensoren\"\n",
    "    input_meta_2.content = _metadata_fb.ContentT()\n",
    "    input_meta_2.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_2.content.contentProperties.min = 0\n",
    "    input_meta_2.content.contentProperties.max = 1\n",
    "    \n",
    "    input_meta_3 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_3.name = \"Heartrate\"\n",
    "    input_meta_3.description = \"Die Anzahl an Herzschlägen pro Minute\"\n",
    "    input_meta_3.content = _metadata_fb.ContentT()\n",
    "    input_meta_3.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_3.content.contentProperties.min = 20\n",
    "    input_meta_3.content.contentProperties.max = 200\n",
    "    \n",
    "    output_meta_1 = _metadata_fb.TensorMetadataT()\n",
    "    output_meta_1.name = \"Sleeplabel\"\n",
    "    output_meta_1.description = \"Die aktuelle Schlafphase (0=wach, 1=schlafend, 2=leichter Schlaf, 3=REM)\"\n",
    "    output_meta_1.dimensionNames = [\"class\"]\n",
    "    output_meta_1.content = _metadata_fb.ContentT()\n",
    "    output_meta_1.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    output_meta_1.content.contentProperties.min = 0\n",
    "    output_meta_1.content.contentProperties.max = 3\n",
    "    \n",
    "\n",
    "    # Creates subgraph info.\n",
    "    subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "    subgraph.inputTensorMetadata = [input_meta_0, input_meta_1, input_meta_2, input_meta_3]\n",
    "    subgraph.outputTensorMetadata = [output_meta_1]\n",
    "    model_meta.subgraphMetadata = [subgraph]\n",
    "    \n",
    "    b = flatbuffers.Builder(0)\n",
    "    \n",
    "    packed = model_meta.Pack(b)\n",
    "    \n",
    "    b.Finish(\n",
    "        packed,\n",
    "        _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER\n",
    "    )\n",
    "    metadata_buffer = b.Output()\n",
    "    populator = _metadata.MetadataPopulator.with_model_file(model_path)\n",
    "    populator.load_metadata_buffer(metadata_buffer)\n",
    "    populator.populate()\n",
    "    \n",
    "add_metadata_to_model(\"models/sleepPhaseAnalyserV1.tflite\", _MODEL_INFO)"
   ],
   "id": "7d6b459aedcf33a3",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:58:46.858796Z",
     "start_time": "2025-01-13T12:58:46.133149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n",
    "df_train = df_train.dropna()"
   ],
   "id": "45fa4297140dcc5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68465/2381353175.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sparse Categorical Crossentropy",
   "id": "2ad57f47c14dd2a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:45:58.574298Z",
     "start_time": "2025-01-13T13:45:58.571809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_columns = [\n",
    "    \"movementData\",\n",
    "    #\"sleepLevels\",\n",
    "    #\"restlessMoments\",\n",
    "    \"heartrate\",\n",
    "    #\"stress\",\n",
    "    #\"bodyBattery\",\n",
    "    #\"hrv\"\n",
    "]\n",
    "\n",
    "label_names = [\"sleepLevels\"]\n",
    "\n",
    "config = LSTMConfig(\n",
    "    feature_columns=feature_columns,\n",
    "    label_names=label_names,\n",
    "    label_count=4,\n",
    "    n_steps=120,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    scaled_labels=True,\n",
    "    checkpoint_path=\"models/chkp.keras\",\n",
    "    loss_function=\"sparse_categorical_crossentropy\"\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "5d0c8ae91df30008",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Categorical Crossentropy",
   "id": "d5e6b2af560f8665"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:32:06.646589Z",
     "start_time": "2025-01-13T10:32:06.621852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train['awake'] = [1 if d == 0 else 0 for d in df_train['sleepLevels']]\n",
    "df_train['asleep'] = [1 if d == 1 else 0 for d in df_train['sleepLevels']]\n",
    "df_train['lightSleep'] = [1 if d == 2 else 0 for d in df_train['sleepLevels']]\n",
    "df_train['rem'] = [1 if d == 3 else 0 for d in df_train['sleepLevels']]\n",
    "\n",
    "feature_columns = [\n",
    "    \"movementData\",\n",
    "    #\"sleepLevels\",\n",
    "    #\"restlessMoments\",\n",
    "    \"heartrate\",\n",
    "    #\"stress\",\n",
    "    #\"bodyBattery\",\n",
    "    #\"hrv\"\n",
    "]\n",
    "\n",
    "label_names = [\"awake\", \"lightSleep\", \"asleep\", \"rem\"]\n",
    "\n",
    "config = LSTMConfig(\n",
    "    feature_columns=feature_columns,\n",
    "    label_names=label_names,\n",
    "    n_steps=120,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    scaled_labels=True,\n",
    "    checkpoint_path=\"models/chkp.keras\",\n",
    "    loss_function=\"categorical_crossentropy\"\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "7430b0e1bcd8b35a",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Initialisation",
   "id": "c3a32698eef8a732"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:46:52.912793Z",
     "start_time": "2025-01-13T13:46:01.095760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts_lstm.build_model(df_train[feature_columns])\n",
    "ts_lstm.train(dataframe=df_train[feature_columns + label_names])\n",
    "print(\"Initial Training Completed!\")\n",
    "\n",
    "# ts_lstm.convert_to_tflite(\"models/sleepPhaseAnalyserV1.tflite\", df_train)"
   ],
   "id": "1eec50bc72897ded",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_time_sin (InputLayer  [(None, 120, 1)]             0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_time_cos (InputLayer  [(None, 120, 1)]             0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_movementData (InputL  [(None, 120, 1)]             0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " input_heartrate (InputLaye  [(None, 120, 1)]             0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " normalization_20 (Normaliz  (None, 120, 1)               3         ['input_time_sin[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " normalization_21 (Normaliz  (None, 120, 1)               3         ['input_time_cos[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " normalization_22 (Normaliz  (None, 120, 1)               3         ['input_movementData[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " normalization_23 (Normaliz  (None, 120, 1)               3         ['input_heartrate[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " lstm_24 (LSTM)              (None, 64)                   16896     ['normalization_20[0][0]']    \n",
      "                                                                                                  \n",
      " lstm_25 (LSTM)              (None, 64)                   16896     ['normalization_21[0][0]']    \n",
      "                                                                                                  \n",
      " lstm_26 (LSTM)              (None, 64)                   16896     ['normalization_22[0][0]']    \n",
      "                                                                                                  \n",
      " lstm_27 (LSTM)              (None, 64)                   16896     ['normalization_23[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 256)                  0         ['lstm_24[0][0]',             \n",
      " )                                                                   'lstm_25[0][0]',             \n",
      "                                                                     'lstm_26[0][0]',             \n",
      "                                                                     'lstm_27[0][0]']             \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 64)                   16448     ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 4)                    260       ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84304 (329.33 KB)\n",
      "Trainable params: 84292 (329.27 KB)\n",
      "Non-trainable params: 12 (64.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Shape of X: (29674, 120, 4)\n",
      "Shape of y: (29674, 1)\n",
      "Epoch 1/2\n",
      "742/742 [==============================] - 23s 27ms/step - loss: 0.6557 - accuracy: 0.8194\n",
      "Epoch 2/2\n",
      "742/742 [==============================] - 22s 29ms/step - loss: 0.6418 - accuracy: 0.8204\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.6006 - accuracy: 0.8339\n",
      "Loss: [0.600570023059845, 0.8338668942451477]\n",
      "Initial Training Completed!\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:43:54.800055Z",
     "start_time": "2025-01-10T15:43:54.222256Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.load_model(\"models/sleepPhaseAnalyserV1.keras\")",
   "id": "9b5d72eed4aaf897",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:47:22.634683Z",
     "start_time": "2025-01-13T13:47:22.585302Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.save_model(\"models/sleepPhaseAnalyserV1.keras\")",
   "id": "df452a55c88e3f04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:54:35.863215Z",
     "start_time": "2025-01-13T13:47:26.144688Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.convert_to_tflite(\"models/sleepPhaseAnalyserV1.tflite\", df_train)",
   "id": "5858cd8cd2ffb018",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temp SavedModel\n",
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'tmp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  Args:\n",
      "    args_0: [<1>, <2>, <3>, <4>]\n",
      "      <1>: float32 Tensor, shape=(None, 120, 1)\n",
      "      <2>: float32 Tensor, shape=(None, 120, 1)\n",
      "      <3>: float32 Tensor, shape=(None, 120, 1)\n",
      "      <4>: float32 Tensor, shape=(None, 120, 1)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(None, 4)\n",
      "Converting SavedModel to tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 14:47:27.719950: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-01-13 14:47:27.719970: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-01-13 14:47:27.720111: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: tmp\n",
      "2025-01-13 14:47:27.722029: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-01-13 14:47:27.722042: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: tmp\n",
      "2025-01-13 14:47:27.727143: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-01-13 14:47:27.792769: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: tmp\n",
      "2025-01-13 14:47:27.838044: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 117932 microseconds.\n",
      "2025-01-13 14:47:27.957426: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<1x?x64xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "2025-01-13 14:47:27.962894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-13 14:47:27.963030: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp SavedModel\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utils",
   "id": "ee35f19675a17710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:44:51.013020Z",
     "start_time": "2025-01-10T15:44:51.009939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_all_files(path):\n",
    "    try:\n",
    "        files = []\n",
    "\n",
    "        for f in os.listdir(path):\n",
    "            filepath = os.path.join(path, f)\n",
    "            if os.path.isfile(filepath):  # Prüft, ob es sich um eine Datei handelt\n",
    "                files.append(f)\n",
    "\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Das Verzeichnis '{path}' wurde nicht gefunden.\")\n",
    "        return []"
   ],
   "id": "5f712c5337735a19",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:57:59.571431Z",
     "start_time": "2025-01-10T15:47:21.455424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "ts_lstm.load_model(\"models/sleepPhaseAnalyserV1.keras\")\n",
    "\n",
    "files = list_all_files(\"data/4_squashed_format/\")\n",
    "\n",
    "for file in files:\n",
    "    print(\"Start Training with \" + file)\n",
    "    df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n",
    "    df_train = df_train.dropna()\n",
    "    \n",
    "    ts_lstm.train(dataframe=df_train[feature_columns + label_names])\n",
    "    ts_lstm.save_model(\"models/sleepPhaseAnalyserV1.keras\")\n",
    "print(\"Training completed!\")"
   ],
   "id": "bb3684e5744f60e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training with2024-08-23.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "704/704 [==============================] - 23s 29ms/step - loss: 0.2386 - accuracy: 0.7857\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 0.2385 - accuracy: 0.7857\n",
      "176/176 [==============================] - 3s 9ms/step - loss: 0.2405 - accuracy: 0.7806\n",
      "Loss: [0.2404816746711731, 0.7806004881858826]\n",
      "Model saved!\n",
      "Start Training with2024-09-05.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "763/763 [==============================] - 23s 30ms/step - loss: 0.1577 - accuracy: 0.8578\n",
      "Epoch 2/2\n",
      "763/763 [==============================] - 23s 30ms/step - loss: 0.1521 - accuracy: 0.8578\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 0.1431 - accuracy: 0.8609\n",
      "Loss: [0.14311617612838745, 0.8608880639076233]\n",
      "Model saved!\n",
      "Start Training with2024-09-08.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "695/695 [==============================] - 21s 30ms/step - loss: 0.2236 - accuracy: 0.5177\n",
      "Epoch 2/2\n",
      "695/695 [==============================] - 21s 30ms/step - loss: 0.1868 - accuracy: 0.5203\n",
      "174/174 [==============================] - 2s 9ms/step - loss: 0.1655 - accuracy: 0.5379\n",
      "Loss: [0.16548559069633484, 0.5378801226615906]\n",
      "Model saved!\n",
      "Start Training with2024-08-22.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "544/544 [==============================] - 17s 30ms/step - loss: 0.2978 - accuracy: 0.3873\n",
      "Epoch 2/2\n",
      "544/544 [==============================] - 16s 30ms/step - loss: 0.2796 - accuracy: 0.3875\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2799 - accuracy: 0.3811\n",
      "Loss: [0.27985647320747375, 0.38114941120147705]\n",
      "Model saved!\n",
      "Start Training with2024-09-19.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "723/723 [==============================] - 24s 33ms/step - loss: 0.2514 - accuracy: 0.7644\n",
      "Epoch 2/2\n",
      "723/723 [==============================] - 24s 33ms/step - loss: 0.2459 - accuracy: 0.7652\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.2380 - accuracy: 0.7669\n",
      "Loss: [0.23804061114788055, 0.7669029831886292]\n",
      "Model saved!\n",
      "Start Training with2024-09-01.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "544/544 [==============================] - 16s 30ms/step - loss: 0.2108 - accuracy: 0.8643\n",
      "Epoch 2/2\n",
      "544/544 [==============================] - 19s 35ms/step - loss: 0.2039 - accuracy: 0.8633\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.2459 - accuracy: 0.8535\n",
      "Loss: [0.24593764543533325, 0.8534958362579346]\n",
      "Model saved!\n",
      "Start Training with2024-08-27.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "674/674 [==============================] - 20s 29ms/step - loss: 0.1689 - accuracy: 0.5985\n",
      "Epoch 2/2\n",
      "674/674 [==============================] - 20s 30ms/step - loss: 0.1552 - accuracy: 0.5961\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.1502 - accuracy: 0.5931\n",
      "Loss: [0.1501680165529251, 0.593135416507721]\n",
      "Model saved!\n",
      "Start Training with2024-08-29.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.1271 - accuracy: 0.8700\n",
      "Epoch 2/2\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.1214 - accuracy: 0.8704\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1304 - accuracy: 0.8721\n",
      "Loss: [0.13041536509990692, 0.8721362948417664]\n",
      "Model saved!\n",
      "Start Training with2024-08-21.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "742/742 [==============================] - 22s 30ms/step - loss: 0.2381 - accuracy: 0.8204\n",
      "Epoch 2/2\n",
      "742/742 [==============================] - 25s 34ms/step - loss: 0.2352 - accuracy: 0.8204\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.2266 - accuracy: 0.8339\n",
      "Loss: [0.22661004960536957, 0.8338668942451477]\n",
      "Model saved!\n",
      "Start Training with2024-09-03.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "647/647 [==============================] - 23s 35ms/step - loss: 0.2967 - accuracy: 0.8558\n",
      "Epoch 2/2\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.3124 - accuracy: 0.8558\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.3320 - accuracy: 0.8457\n",
      "Loss: [0.33202844858169556, 0.8456777930259705]\n",
      "Model saved!\n",
      "Start Training with2024-09-06.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "644/644 [==============================] - 19s 29ms/step - loss: 0.2676 - accuracy: 0.7725\n",
      "Epoch 2/2\n",
      "644/644 [==============================] - 20s 31ms/step - loss: 0.2647 - accuracy: 0.7725\n",
      "161/161 [==============================] - 2s 11ms/step - loss: 0.2615 - accuracy: 0.7789\n",
      "Loss: [0.2615232765674591, 0.7788573503494263]\n",
      "Model saved!\n",
      "Start Training with2024-08-30.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "747/747 [==============================] - 25s 34ms/step - loss: 0.2054 - accuracy: 0.8287\n",
      "Epoch 2/2\n",
      "747/747 [==============================] - 23s 31ms/step - loss: 0.2038 - accuracy: 0.8287\n",
      "187/187 [==============================] - 2s 9ms/step - loss: 0.1922 - accuracy: 0.8417\n",
      "Loss: [0.19219979643821716, 0.8417266011238098]\n",
      "Model saved!\n",
      "Start Training with2024-09-02.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "693/693 [==============================] - 21s 30ms/step - loss: 0.3681 - accuracy: 0.7315\n",
      "Epoch 2/2\n",
      "693/693 [==============================] - 24s 35ms/step - loss: 0.3656 - accuracy: 0.7320\n",
      "174/174 [==============================] - 2s 11ms/step - loss: 0.3597 - accuracy: 0.7287\n",
      "Loss: [0.3596736788749695, 0.7286514043807983]\n",
      "Model saved!\n",
      "Training completed!\n"
     ]
    }
   ],
   "execution_count": 95
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
