{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T13:33:04.770616Z",
     "start_time": "2025-01-10T13:33:04.767629Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import flatbuffers\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Concatenate, Normalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support import metadata as _metadata"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:18:25.663992Z",
     "start_time": "2025-01-10T15:18:25.650165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMConfig(BaseModel):\n",
    "    feature_columns: list[str]\n",
    "    label_names: list[str]\n",
    "    scaled_labels: bool\n",
    "    n_steps: int = Field(default=50, ge=1)\n",
    "    batch_size: int = Field(default=32, ge=1)\n",
    "    epochs: int = Field(default=20, ge=1)\n",
    "    test_size: float = Field(default=0.2, ge=0, le=1)\n",
    "    checkpoint_path: str = Field(default=\"\")\n",
    "\n",
    "\n",
    "class TimeSeriesLSTM:\n",
    "\n",
    "    def __init__(self, config: LSTMConfig):\n",
    "        self.config = config\n",
    "        self.model: Model = None\n",
    "\n",
    "    def _create_segments(self, data: pd.Series, n_steps):\n",
    "        num_samples = len(data) - n_steps + 1\n",
    "        return np.array([data[i:i + n_steps] for i in range(num_samples)]).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    def dataframe_to_pred_data(self, df_prediction: pd.DataFrame):\n",
    "        features = self.config.feature_columns\n",
    "        n_steps = self.config.n_steps\n",
    "        \n",
    "        X = []\n",
    "        # Create Time Series in Timestamp\n",
    "        segmented_data = self._create_segments(df_prediction.index.asi8, n_steps)\n",
    "        X.append(segmented_data[:, :, np.newaxis])\n",
    "        \n",
    "        for feature in features:\n",
    "            segmented_data = self._create_segments(df_prediction[feature], n_steps)\n",
    "            X.append(segmented_data[:, :, np.newaxis])\n",
    "        \n",
    "        return np.concatenate(X, axis=2)\n",
    "    \n",
    "\n",
    "    def dataframe_to_train_data(self, df_training: pd.DataFrame):\n",
    "        features = self.config.feature_columns\n",
    "        labels = self.config.label_names\n",
    "        n_steps = self.config.n_steps\n",
    "        \n",
    "        X = self.dataframe_to_pred_data(df_training[features])\n",
    "        \n",
    "        label_arrays = [self._create_segments(df_training[label], n_steps)[:, -1] for label in labels]\n",
    "        y = np.stack(label_arrays, axis=1)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "        print(\"Model loaded!\")\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "    def build_model(self, adaptation_data):\n",
    "        inputs = []\n",
    "        lstm_outputs = []\n",
    "        \n",
    "        for feature_idx in range(len(self.config.feature_columns)+1):\n",
    "            if feature_idx > 0:\n",
    "                feature_name = self.config.feature_columns[feature_idx-1]\n",
    "            else:\n",
    "                feature_name = \"Time\"\n",
    "            \n",
    "            input_tensor = Input(shape=(self.config.n_steps, 1), dtype=tf.float32, name=f'input_{feature_name}')\n",
    "            inputs.append(input_tensor)\n",
    "            normalization = Normalization()\n",
    "            normalization.adapt(adaptation_data)\n",
    "            lstm = LSTM(64, return_sequences=False, dtype=tf.float32)\n",
    "            lstm_outputs.append(lstm(normalization(input_tensor)))\n",
    "\n",
    "        merged = Concatenate(axis=1)(lstm_outputs)\n",
    "        \n",
    "        x = Dense(64, activation='relu')(merged)\n",
    "        output = Dense(len(self.config.label_names))(x)\n",
    "        \n",
    "        self.model = Model(inputs=inputs, outputs=output)\n",
    "        self.model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['accuracy'])\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def train(self, dataframe: pd.DataFrame):\n",
    "        X, y = self.dataframe_to_train_data(dataframe)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.config.test_size, random_state=69)\n",
    "        \n",
    "        X_train_split = np.split(X_train, indices_or_sections=3, axis=2)\n",
    "        X_test_split = np.split(X_test, indices_or_sections=3, axis=2)\n",
    "\n",
    "        X_train_squeeze = [arr.squeeze(axis=2) for arr in X_train_split]\n",
    "        X_test_squeeze = [arr.squeeze(axis=2) for arr in X_test_split]\n",
    "\n",
    "        self.model.fit(X_train_squeeze, y_train, epochs=self.config.epochs, batch_size=self.config.batch_size)\n",
    "        loss = self.model.evaluate(X_test_squeeze, y_test)\n",
    "        \n",
    "        print(f\"Loss: {loss}\")\n",
    "\n",
    "    def predict(self, input_data: pd.DataFrame):\n",
    "        X = self.dataframe_to_pred_data(input_data)       \n",
    "        X_split = np.split(X, indices_or_sections=3, axis=2)\n",
    "        X_squeeze = [arr.squeeze(axis=2) for arr in X_split]\n",
    "        return self.model.predict(X_squeeze)\n",
    "\n",
    "\n",
    "def generate_representative_data(data: pd.DataFrame, config: LSTMConfig):\n",
    "    X = []\n",
    "    \n",
    "    for i in range(len(data) - config.n_steps + 1):\n",
    "        X.append(data.iloc[i:i + config.n_steps].values)  # Hol dir die Zeitfenster\n",
    "    \n",
    "    X = np.array(X)       \n",
    "\n",
    "    for i, sample in enumerate(X):\n",
    "        sample = sample.reshape(1, config.n_steps, 1)  # Form anpassen\n",
    "        yield {f'input_{config.feature_columns[i]}': sample}\n",
    "\n",
    "def convert_model_to_tflite(keras_path, tflite_path, representative_dataset, config: LSTMConfig): \n",
    "    print(\"Creating temp SavedModel!\")\n",
    "    keras_model = tf.keras.models.load_model(keras_path)\n",
    "    keras_model.export(\"tmp\")\n",
    "    \n",
    "    print(\"Converting SavedModel to tflite!\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=\"tmp\")\n",
    "    converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS , tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.inference_output_type = tf.float32\n",
    "\n",
    "    # Wird benötigt für den Quantizierungs-Prozess\n",
    "    converter.representative_dataset = lambda: generate_representative_data(representative_dataset, config)\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "        \n",
    "    print(\"Removing temp SavedModel!\")\n",
    "    shutil.rmtree(\"tmp\")\n",
    "    print(\"Finished!\")"
   ],
   "id": "d5da6b15ac1ab32f",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "639bc7eda3696212"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Datensatz\n",
    "\n",
    "### Es wird ein zufälliger Datensatz erzeugt"
   ],
   "id": "cbb86afd06a2533d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:21:15.636747Z",
     "start_time": "2024-12-20T12:21:15.627849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zufällige Datensätze erzeugen\n",
    "train_dates = pd.date_range(start='2020-01-01', periods=10000)\n",
    "pred_dates = pd.date_range(start='2021-01-01', periods=100)\n",
    "\n",
    "train_labels = np.random.randint(low=0, high=3, size=10000)\n",
    "\n",
    "train_data = {\n",
    "    'feature1': np.random.rand(10000).astype(np.float32),\n",
    "    'feature2': np.random.rand(10000).astype(np.float32),\n",
    "    'feature3': np.random.rand(10000).astype(np.float32),\n",
    "    'sleep': np.array([1 if lb == 0 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'awake': np.array([1 if lb == 1 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'rem': np.array([1 if lb == 2 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'light': np.array([1 if lb == 3 else 0 for lb in train_labels]).astype(np.float32)\n",
    "}\n",
    "\n",
    "pred_data = {\n",
    "    'feature1': np.random.rand(100).astype(np.float32),\n",
    "    'feature2': np.random.rand(100).astype(np.float32),\n",
    "    'feature3': np.random.rand(100).astype(np.float32),\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(train_data, index=train_dates)\n",
    "df_pred = pd.DataFrame(pred_data, index=pred_dates)"
   ],
   "id": "742904d59b89a4bc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Initialisierung\n",
    "\n",
    "### Das Model wird mit gegebener Konfiguration initialisiert"
   ],
   "id": "6561d11ae654ea5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:25:45.766856Z",
     "start_time": "2025-01-10T13:25:45.166190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konfiguration erstellen und Modell instanziieren\n",
    "config = LSTMConfig(\n",
    "    feature_columns=['time', 'movement', 'heartrate'],\n",
    "    label_names=['sleeplabel'],\n",
    "    scaled_labels=False,\n",
    "    n_steps=25,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "f89d0ab3c6eb02d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 14:25:45.335999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_time (InputLayer)     [(None, 25, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " input_movement (InputLayer  [(None, 25, 1)]              0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_heartrate (InputLaye  [(None, 25, 1)]              0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 64)                   16896     ['input_time[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 64)                   16896     ['input_movement[0][0]']      \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 64)                   16896     ['input_heartrate[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 192)                  0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   12352     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    65        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63105 (246.50 KB)\n",
      "Trainable params: 63105 (246.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trainings-Step",
   "id": "fc712c222bf5b4ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:23:50.504600Z",
     "start_time": "2024-12-20T12:23:19.266398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start des Trainings\n",
    "ts_lstm.train(dataframe=df_train)"
   ],
   "id": "34a68e059d933c63",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTMConfig' object has no attribute 'label_column'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Start des Trainings\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mts_lstm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[24], line 65\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.train\u001B[0;34m(self, dataframe)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataframe: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[0;32m---> 65\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m     X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtest_size, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m69\u001B[39m)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mepochs, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size)\n",
      "Cell \u001B[0;32mIn[24], line 26\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.preprocess_data\u001B[0;34m(self, dataframe, train_data)\u001B[0m\n\u001B[1;32m     24\u001B[0m         labels \u001B[38;5;241m=\u001B[39m dataframe[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlabel_column] \u001B[38;5;241m/\u001B[39m dataframe[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlabel_column]\u001B[38;5;241m.\u001B[39mmax()\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 26\u001B[0m         labels \u001B[38;5;241m=\u001B[39m dataframe[\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_column\u001B[49m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     28\u001B[0m X, y \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(scaled_data) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mn_steps):\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/pydantic/main.py:856\u001B[0m, in \u001B[0;36mBaseModel.__getattr__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(item)  \u001B[38;5;66;03m# Raises AttributeError if appropriate\u001B[39;00m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[0;32m--> 856\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LSTMConfig' object has no attribute 'label_column'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prediction Step",
   "id": "80a043aa621074c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:13:31.300816Z",
     "start_time": "2024-10-15T12:13:31.104657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modell Predictions erzeugen\n",
    "\n",
    "pred_results = ts_lstm.predict(df_pred)\n",
    "\n",
    "df_pred_no_time = pd.DataFrame(pred_data)\n",
    "for index, row in df_pred_no_time.iterrows():\n",
    "    if index < config.n_steps:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", \"Not enough data\")\n",
    "    else:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", pred_results[index-config.n_steps])"
   ],
   "id": "c7d7dcacae7fea46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "F: 0.51403713 0.19882914 0.5911012  P: Not enough data\n",
      "F: 0.11934123 0.40530437 0.89096767  P: Not enough data\n",
      "F: 0.38564697 0.29791084 0.19773565  P: Not enough data\n",
      "F: 0.6703891 0.71410924 0.5589309  P: Not enough data\n",
      "F: 0.6856324 0.26695275 0.604667  P: Not enough data\n",
      "F: 0.37407333 0.5748829 0.76460654  P: Not enough data\n",
      "F: 0.045838956 0.85503596 0.37089372  P: Not enough data\n",
      "F: 0.11443184 0.062243324 0.710078  P: Not enough data\n",
      "F: 0.35948795 0.42584494 0.7620492  P: Not enough data\n",
      "F: 0.5214783 0.36130518 0.88608074  P: Not enough data\n",
      "F: 0.9309409 0.4325166 0.7721853  P: Not enough data\n",
      "F: 0.5279233 0.8800477 0.5392751  P: Not enough data\n",
      "F: 0.33663088 0.6341414 0.3659117  P: Not enough data\n",
      "F: 0.8563349 0.4537363 0.38099846  P: Not enough data\n",
      "F: 0.7088956 0.10979994 0.4552031  P: Not enough data\n",
      "F: 0.42051426 0.9532006 0.94734293  P: Not enough data\n",
      "F: 0.62419176 0.5616601 0.22580338  P: Not enough data\n",
      "F: 0.19315931 0.49989152 0.94404525  P: Not enough data\n",
      "F: 0.13220085 0.38574183 0.85863066  P: Not enough data\n",
      "F: 0.48927695 0.560172 0.011551256  P: Not enough data\n",
      "F: 0.10607543 0.7570634 0.8861291  P: Not enough data\n",
      "F: 0.6636275 0.32873437 0.823422  P: Not enough data\n",
      "F: 0.08417101 0.9938953 0.8140583  P: Not enough data\n",
      "F: 0.7712223 0.6914217 0.5376309  P: Not enough data\n",
      "F: 0.28833458 0.406496 0.1978169  P: Not enough data\n",
      "F: 0.3983846 0.95207506 0.7505153  P: [0.4747945]\n",
      "F: 0.3946925 0.8963494 0.3028491  P: [0.47674352]\n",
      "F: 0.05294987 0.28149277 0.39824852  P: [0.4765578]\n",
      "F: 0.32014358 0.67472327 0.7792752  P: [0.47411436]\n",
      "F: 0.6616065 0.05735944 0.5675902  P: [0.47449017]\n",
      "F: 0.63627666 0.56664836 0.048654612  P: [0.48015147]\n",
      "F: 0.7836055 0.27310893 0.54620373  P: [0.48141724]\n",
      "F: 0.6484505 0.09207389 0.8531832  P: [0.48441964]\n",
      "F: 0.08989168 0.44443265 0.8396912  P: [0.48345304]\n",
      "F: 0.23692825 0.14912888 0.705546  P: [0.47215357]\n",
      "F: 0.25583413 0.16654022 0.43946144  P: [0.4717213]\n",
      "F: 0.90758824 0.054478835 0.55237436  P: [0.472692]\n",
      "F: 0.54202956 0.34710947 0.7996528  P: [0.4859445]\n",
      "F: 0.8535665 0.30902532 0.61588776  P: [0.47387305]\n",
      "F: 0.13289605 0.4401018 0.5260575  P: [0.48000765]\n",
      "F: 0.4949505 0.40676832 0.98499477  P: [0.47138277]\n",
      "F: 0.5682406 0.32822976 0.65451807  P: [0.47098333]\n",
      "F: 0.06937735 0.44287038 0.003226418  P: [0.47277576]\n",
      "F: 0.9737601 0.61246467 0.6494063  P: [0.4554853]\n",
      "F: 0.4491022 0.53566504 0.36772522  P: [0.4763246]\n",
      "F: 0.9589011 0.16532339 0.25872746  P: [0.47488588]\n",
      "F: 0.35778314 0.53696716 0.47385022  P: [0.48181242]\n",
      "F: 0.7914795 0.32677048 0.029292451  P: [0.47396198]\n",
      "F: 0.35182625 0.571196 0.27259728  P: [0.47975123]\n",
      "F: 0.65045106 0.5139587 0.87588966  P: [0.4820324]\n",
      "F: 0.23736574 0.19045915 0.10954196  P: [0.47940883]\n",
      "F: 0.26739395 0.011894234 0.9883093  P: [0.4783193]\n",
      "F: 0.6599377 0.07068916 0.8319202  P: [0.49350882]\n",
      "F: 0.28839165 0.8456586 0.6589199  P: [0.49697053]\n",
      "F: 0.3723383 0.60607576 0.69709474  P: [0.48417118]\n",
      "F: 0.96213895 0.66323584 0.39301363  P: [0.47717944]\n",
      "F: 0.97018456 0.52318275 0.12182373  P: [0.48492488]\n",
      "F: 0.6433087 0.7741509 0.5152273  P: [0.4877857]\n",
      "F: 0.5384767 0.08750506 0.22002523  P: [0.48532793]\n",
      "F: 0.8372823 0.37949324 0.72962517  P: [0.48379055]\n",
      "F: 0.8990525 0.22580017 0.18464856  P: [0.48306602]\n",
      "F: 0.38456175 0.42463702 0.82179976  P: [0.48359343]\n",
      "F: 0.22523522 0.33518478 0.3476741  P: [0.47506094]\n",
      "F: 0.27739954 0.22606632 0.6430577  P: [0.47542217]\n",
      "F: 0.53853005 0.11766241 0.062447235  P: [0.4764195]\n",
      "F: 0.8546604 0.32708746 0.31126377  P: [0.4810237]\n",
      "F: 0.8320798 0.5203937 0.23040089  P: [0.48700133]\n",
      "F: 0.7700596 0.37310278 0.22462413  P: [0.4888732]\n",
      "F: 0.8811286 0.33805534 0.3160066  P: [0.49077147]\n",
      "F: 0.39301956 0.94850457 0.78877866  P: [0.49121043]\n",
      "F: 0.9404266 0.2587561 0.7262606  P: [0.4834284]\n",
      "F: 0.86999303 0.16029647 0.9210936  P: [0.4847135]\n",
      "F: 0.95227265 0.8303039 0.57670903  P: [0.48483428]\n",
      "F: 0.90284497 0.55347264 0.037326545  P: [0.47911057]\n",
      "F: 0.009861089 0.09669762 0.56428945  P: [0.48392802]\n",
      "F: 0.1313332 0.5159357 0.18208331  P: [0.49755904]\n",
      "F: 0.98926836 0.866441 0.27117586  P: [0.48962212]\n",
      "F: 0.54463947 0.687957 0.46692324  P: [0.49957368]\n",
      "F: 0.33682856 0.118074484 0.91983795  P: [0.49695292]\n",
      "F: 0.3379626 0.06699804 0.35189778  P: [0.4903919]\n",
      "F: 0.102978736 0.20571272 0.7865161  P: [0.48796052]\n",
      "F: 0.036181226 0.2901685 0.8909183  P: [0.49159068]\n",
      "F: 0.13929659 0.38210917 0.20137511  P: [0.49886402]\n",
      "F: 0.6124165 0.46874627 0.69383776  P: [0.4895938]\n",
      "F: 0.16323213 0.8740749 0.5594947  P: [0.48631874]\n",
      "F: 0.66703963 0.66398436 0.7964448  P: [0.4803588]\n",
      "F: 0.5614926 0.9724125 0.02677405  P: [0.47407672]\n",
      "F: 0.2485148 0.4724953 0.4603526  P: [0.4737911]\n",
      "F: 0.67865247 0.60557866 0.13872944  P: [0.47456843]\n",
      "F: 0.79949206 0.414929 0.6851424  P: [0.4815458]\n",
      "F: 0.11192233 0.77361333 0.521974  P: [0.48248243]\n",
      "F: 0.8939152 0.5715325 0.108909816  P: [0.47286963]\n",
      "F: 0.39729017 0.73760843 0.35122886  P: [0.47731414]\n",
      "F: 0.5152495 0.06440042 0.17496228  P: [0.4808576]\n",
      "F: 0.53784806 0.47035545 0.9190049  P: [0.47928366]\n",
      "F: 0.27196544 0.09998814 0.23230983  P: [0.47511142]\n",
      "F: 0.37764835 0.9940766 0.46451226  P: [0.4732932]\n",
      "F: 0.44830796 0.6026568 0.09229851  P: [0.47669733]\n",
      "F: 0.36787257 0.8829762 0.49822736  P: [0.4812325]\n",
      "F: 0.8515667 0.2094194 0.81918967  P: [0.48210216]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modell Speichern, Laden und Konvertieren",
   "id": "62f4cc1909cebe6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:20:35.348596Z",
     "start_time": "2024-12-17T17:20:35.320025Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.save_model(\"TestModel.keras\")",
   "id": "209c16dc220efd3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:33:31.855675Z",
     "start_time": "2024-12-17T17:33:31.697605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lade das Modell aus der TF-Lite Datei\n",
    "ts_lstm.load_model(\"TestModel.keras\")"
   ],
   "id": "4830dba6364866cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:37:10.832888Z",
     "start_time": "2024-12-17T17:37:10.785422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ModelSpecificInfo(BaseModel):\n",
    "    name: str\n",
    "    version: float\n",
    "    num_inputs: int\n",
    "    num_outputs: int        \n",
    "\n",
    "\n",
    "_MODEL_INFO = ModelSpecificInfo(\n",
    "        name=\"Testmodell\",\n",
    "        version=1.0,\n",
    "        num_inputs=3,\n",
    "        num_outputs=2\n",
    ")\n",
    "\n",
    "\n",
    "def add_metadata_to_model(model_path: str, metadata: ModelSpecificInfo):\n",
    "    \n",
    "    model_meta = _metadata_fb.ModelMetadataT()\n",
    "    model_meta.name = metadata.name\n",
    "    model_meta.description = \"Ein zufälliges Modell\"\n",
    "    \n",
    "    input_meta_0 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_0.name = \"Time\"\n",
    "    input_meta_0.dimensionNames = ['sin', 'cos']\n",
    "    input_meta_0.description = \"Die Tageszeit an dem der Wert aufgenommen wurde\"\n",
    "    input_meta_0.content = _metadata_fb.ContentT()\n",
    "    input_meta_0.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_0.content.contentProperties.min = 0\n",
    "    input_meta_0.content.contentProperties.max = 10\n",
    "    \n",
    "    input_meta_1 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_1.name = \"Movement\"\n",
    "    input_meta_1.description = \"Die Bewegungsintensität gemittelt aus den Beschleunigungssensoren\"\n",
    "    input_meta_1.content = _metadata_fb.ContentT()\n",
    "    input_meta_1.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_1.content.contentProperties.min = 0\n",
    "    input_meta_1.content.contentProperties.max = 1\n",
    "    \n",
    "    input_meta_2 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_2.name = \"Heartrate\"\n",
    "    input_meta_2.description = \"Die Anzahl an Herzschlägen pro Minute\"\n",
    "    input_meta_2.content = _metadata_fb.ContentT()\n",
    "    input_meta_2.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_2.content.contentProperties.min = 0\n",
    "    input_meta_2.content.contentProperties.max = 1\n",
    "    \n",
    "    output_meta_1 = _metadata_fb.TensorMetadataT()\n",
    "    output_meta_1.name = \"Sleeplabel\"\n",
    "    output_meta_1.description = \"Die aktuelle Schlafphase\"\n",
    "    \n",
    "\n",
    "    # Creates subgraph info.\n",
    "    subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "    subgraph.inputTensorMetadata = [input_meta_0, input_meta_1,input_meta_2]\n",
    "    subgraph.outputTensorMetadata = [output_meta_1]\n",
    "    model_meta.subgraphMetadata = [subgraph]\n",
    "    \n",
    "    b = flatbuffers.Builder(0)\n",
    "    \n",
    "    packed = model_meta.Pack(b)\n",
    "    \n",
    "    b.Finish(\n",
    "        packed,\n",
    "        _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER\n",
    "    )\n",
    "    metadata_buffer = b.Output()\n",
    "    populator = _metadata.MetadataPopulator.with_model_file(model_path)\n",
    "    populator.load_metadata_buffer(metadata_buffer)\n",
    "    populator.populate()\n",
    "    \n",
    "add_metadata_to_model(\"TestModel.tflite\", _MODEL_INFO)"
   ],
   "id": "7d6b459aedcf33a3",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of input tensors (1) should match the number of input tensor metadata (3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 69\u001B[0m\n\u001B[1;32m     66\u001B[0m     populator\u001B[38;5;241m.\u001B[39mload_metadata_buffer(metadata_buffer)\n\u001B[1;32m     67\u001B[0m     populator\u001B[38;5;241m.\u001B[39mpopulate()\n\u001B[0;32m---> 69\u001B[0m \u001B[43madd_metadata_to_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTestModel.tflite\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_MODEL_INFO\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[26], line 66\u001B[0m, in \u001B[0;36madd_metadata_to_model\u001B[0;34m(model_path, metadata)\u001B[0m\n\u001B[1;32m     64\u001B[0m metadata_buffer \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mOutput()\n\u001B[1;32m     65\u001B[0m populator \u001B[38;5;241m=\u001B[39m _metadata\u001B[38;5;241m.\u001B[39mMetadataPopulator\u001B[38;5;241m.\u001B[39mwith_model_file(model_path)\n\u001B[0;32m---> 66\u001B[0m \u001B[43mpopulator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_metadata_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetadata_buffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m populator\u001B[38;5;241m.\u001B[39mpopulate()\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow_lite_support/metadata/python/metadata.py:302\u001B[0m, in \u001B[0;36mMetadataPopulator.load_metadata_buffer\u001B[0;34m(self, metadata_buf)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m metadata_buf:\n\u001B[1;32m    300\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe metadata to be populated is empty.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetadata_buf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;66;03m# Gets the minimum metadata parser version of the metadata_buf.\u001B[39;00m\n\u001B[1;32m    305\u001B[0m min_version \u001B[38;5;241m=\u001B[39m _pywrap_metadata_version\u001B[38;5;241m.\u001B[39mGetMinimumMetadataParserVersion(\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28mbytes\u001B[39m(metadata_buf))\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow_lite_support/metadata/python/metadata.py:631\u001B[0m, in \u001B[0;36mMetadataPopulator._validate_metadata\u001B[0;34m(self, metadata_buf)\u001B[0m\n\u001B[1;32m    629\u001B[0m num_input_meta \u001B[38;5;241m=\u001B[39m model_meta\u001B[38;5;241m.\u001B[39mSubgraphMetadata(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mInputTensorMetadataLength()\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_input_tensors \u001B[38;5;241m!=\u001B[39m num_input_meta:\n\u001B[0;32m--> 631\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    632\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of input tensors (\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m) should match the number of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    633\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput tensor metadata (\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(num_input_tensors,\n\u001B[1;32m    634\u001B[0m                                            num_input_meta))\n\u001B[1;32m    635\u001B[0m num_output_tensors \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mSubgraphs(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mOutputsLength()\n\u001B[1;32m    636\u001B[0m num_output_meta \u001B[38;5;241m=\u001B[39m model_meta\u001B[38;5;241m.\u001B[39mSubgraphMetadata(\n\u001B[1;32m    637\u001B[0m     \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mOutputTensorMetadataLength()\n",
      "\u001B[0;31mValueError\u001B[0m: The number of input tensors (1) should match the number of input tensor metadata (3)"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:33:55.820056Z",
     "start_time": "2024-12-17T17:33:54.866991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konvertiere das Keras-Modell in ein tflite-Modell\n",
    "convert_model_to_tflite(\"TestModel.keras\", \"TestModel.tflite\", df_pred, config)"
   ],
   "id": "c5bcafd41e5d9483",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temp SavedModel!\n",
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'tmp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  Args:\n",
      "    args_0: float32 Tensor, shape=(None, 25, 3)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(None, 1)\n",
      "Converting SavedModel to tflite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 18:33:55.480951: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp SavedModel!\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 18:33:55.480970: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-12-17 18:33:55.481197: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: tmp\n",
      "2024-12-17 18:33:55.481761: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-12-17 18:33:55.481770: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: tmp\n",
      "2024-12-17 18:33:55.483050: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-12-17 18:33:55.483493: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-12-17 18:33:55.508332: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: tmp\n",
      "2024-12-17 18:33:55.523818: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 42619 microseconds.\n",
      "2024-12-17 18:33:55.548207: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-17 18:33:55.613441: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<1x?x64xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "2024-12-17 18:33:55.628484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 18:33:55.628626: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 21 nodes with 2 partitions.\n",
      "\n",
      "2024-12-17 18:33:55.705019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 18:33:55.705151: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:25:58.144653Z",
     "start_time": "2025-01-10T15:22:17.721671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "feature_columns = [\n",
    "    \"movementData\",\n",
    "    #\"sleepLevels\",\n",
    "    #\"restlessMoments\",\n",
    "    \"heartrate\",\n",
    "    #\"stress\",\n",
    "    #\"bodyBattery\",\n",
    "    #\"hrv\"\n",
    "]\n",
    "\n",
    "label_names = ['sleepLevels']\n",
    "\n",
    "config = LSTMConfig(\n",
    "    feature_columns=feature_columns,\n",
    "    label_names=label_names,\n",
    "    n_steps=120,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    scaled_labels=True,\n",
    "    checkpoint_path=\"models/chkp.keras\")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)\n",
    "ts_lstm.build_model(df_train[feature_columns])\n",
    "\n",
    "\n",
    "ts_lstm.train(dataframe=df_train[feature_columns + label_names])\n",
    "\n",
    "print(\"Training Completed!\")\n",
    "\n",
    "ts_lstm.save_model(\"models/sleepPhaseAnalyserV1.keras\")"
   ],
   "id": "df452a55c88e3f04",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1021010509.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_Time (InputLayer)     [(None, 120, 1)]             0         []                            \n",
      "                                                                                                  \n",
      " input_movementData (InputL  [(None, 120, 1)]             0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " input_heartrate (InputLaye  [(None, 120, 1)]             0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " normalization_66 (Normaliz  (None, 120, 2)               5         ['input_Time[0][0]']          \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " normalization_67 (Normaliz  (None, 120, 2)               5         ['input_movementData[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " normalization_68 (Normaliz  (None, 120, 2)               5         ['input_heartrate[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " lstm_72 (LSTM)              (None, 64)                   17152     ['normalization_66[0][0]']    \n",
      "                                                                                                  \n",
      " lstm_73 (LSTM)              (None, 64)                   17152     ['normalization_67[0][0]']    \n",
      "                                                                                                  \n",
      " lstm_74 (LSTM)              (None, 64)                   17152     ['normalization_68[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenat  (None, 192)                  0         ['lstm_72[0][0]',             \n",
      " e)                                                                  'lstm_73[0][0]',             \n",
      "                                                                     'lstm_74[0][0]']             \n",
      "                                                                                                  \n",
      " dense_60 (Dense)            (None, 64)                   12352     ['concatenate_30[0][0]']      \n",
      "                                                                                                  \n",
      " dense_61 (Dense)            (None, 1)                    65        ['dense_60[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63888 (249.57 KB)\n",
      "Trainable params: 63873 (249.50 KB)\n",
      "Non-trainable params: 15 (72.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "742/742 [==============================] - 21s 25ms/step - loss: 0.2331 - accuracy: 0.8215\n",
      "Epoch 2/10\n",
      "742/742 [==============================] - 20s 27ms/step - loss: 0.2021 - accuracy: 0.8418\n",
      "Epoch 3/10\n",
      "742/742 [==============================] - 20s 28ms/step - loss: 0.1908 - accuracy: 0.8434\n",
      "Epoch 4/10\n",
      "742/742 [==============================] - 21s 28ms/step - loss: 0.1804 - accuracy: 0.8472\n",
      "Epoch 5/10\n",
      "742/742 [==============================] - 21s 29ms/step - loss: 0.1760 - accuracy: 0.8453\n",
      "Epoch 6/10\n",
      "742/742 [==============================] - 22s 29ms/step - loss: 0.1721 - accuracy: 0.8484\n",
      "Epoch 7/10\n",
      "742/742 [==============================] - 21s 29ms/step - loss: 0.1853 - accuracy: 0.8403\n",
      "Epoch 8/10\n",
      "742/742 [==============================] - 22s 29ms/step - loss: 0.2004 - accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "742/742 [==============================] - 21s 29ms/step - loss: 0.1635 - accuracy: 0.8544\n",
      "Epoch 10/10\n",
      "742/742 [==============================] - 22s 30ms/step - loss: 0.1947 - accuracy: 0.8467\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.1701 - accuracy: 0.8753\n",
      "Loss: [0.17012165486812592, 0.8753159046173096]\n",
      "Training Completed!\n",
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-10T15:31:08.636046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "ts_lstm.train(dataframe=df_train[feature_columns + label_names])"
   ],
   "id": "5858cd8cd2ffb018",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/3513699989.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "257/742 [=========>....................] - ETA: 12s - loss: 0.1703 - accuracy: 0.8609"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utils",
   "id": "ee35f19675a17710"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def list_all_files(path):\n",
    "    try:\n",
    "        files = []\n",
    "\n",
    "        for f in os.listdir(path):\n",
    "            filepath = os.path.join(path, f)\n",
    "            if os.path.isfile(filepath):  # Prüft, ob es sich um eine Datei handelt\n",
    "                files.append(f)\n",
    "\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Das Verzeichnis '{path}' wurde nicht gefunden.\")\n",
    "        return []"
   ],
   "id": "5f712c5337735a19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
