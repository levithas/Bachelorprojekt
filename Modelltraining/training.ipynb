{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T12:42:44.525928Z",
     "start_time": "2024-10-28T12:42:42.690199Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import flatbuffers\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support import metadata as _metadata"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 13:42:43.105391: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-28 13:42:43.106918: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 13:42:43.138004: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 13:42:43.138614: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-28 13:42:43.626821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:12.396560Z",
     "start_time": "2024-10-28T12:45:12.366260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMConfig(BaseModel):\n",
    "    feature_columns: list[str]\n",
    "    label_column: str\n",
    "    scaled_labels: bool\n",
    "    n_steps: int = Field(default=50, ge=1)\n",
    "    batch_size: int = Field(default=32, ge=1)\n",
    "    epochs: int = Field(default=20, ge=1)\n",
    "    test_size: float = Field(default=0.2, ge=0, le=1)\n",
    "    checkpoint_path: str = Field(default=\"\")\n",
    "\n",
    "\n",
    "class TimeSeriesLSTM:\n",
    "\n",
    "    def __init__(self, config: LSTMConfig):\n",
    "        self.config = config\n",
    "        self.model: Model = None\n",
    "        self.build_model()\n",
    "\n",
    "    def preprocess_data(self, dataframe: pd.DataFrame, train_data=True):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(dataframe[self.config.feature_columns])\n",
    "        if train_data:\n",
    "            if self.config.scaled_labels:\n",
    "                labels = dataframe[self.config.label_column] / dataframe[self.config.label_column].max()\n",
    "            else:\n",
    "                labels = dataframe[self.config.label_column].values\n",
    "\n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled_data) - self.config.n_steps):\n",
    "            X.append(scaled_data[i:i + self.config.n_steps])\n",
    "            if train_data:\n",
    "                y.append(labels[i + self.config.n_steps])\n",
    "\n",
    "        if train_data:\n",
    "            return np.array(X), np.array(y)\n",
    "        return np.array(X)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "        print(\"Model loaded!\")\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Input((self.config.n_steps, len(self.config.feature_columns)), dtype=tf.float32, name='input_1'))\n",
    "        self.model.add(Dense(32, activation=\"relu\", dtype=tf.float32))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(LSTM(64, return_sequences=False, dtype=tf.float32))\n",
    "        self.model.add(Dense(1, activation=\"linear\", dtype=tf.float32))\n",
    "        self.model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    def train(self, dataframe: pd.DataFrame):\n",
    "        X, y = self.preprocess_data(dataframe)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.config.test_size, random_state=69)\n",
    "\n",
    "        self.model.fit(X_train, y_train, epochs=self.config.epochs, batch_size=self.config.batch_size)\n",
    "\n",
    "        loss = self.model.evaluate(X_test, y_test)\n",
    "        print(f\"Loss: {loss}\")\n",
    "\n",
    "    def predict(self, input_data: pd.DataFrame):\n",
    "        X = self.preprocess_data(input_data, train_data=False)\n",
    "        #X = X.reshape((1, self.config.n_steps, len(self.config.feature_columns)))\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "def generate_representative_data(data: pd.DataFrame, config: LSTMConfig):\n",
    "        X = []\n",
    "        \n",
    "        for i in range(len(data) - config.n_steps + 1):\n",
    "            X.append(data.iloc[i:i + config.n_steps].values)  # Hol dir die Zeitfenster\n",
    "        \n",
    "        X = np.array(X)\n",
    "\n",
    "        for sample in X:\n",
    "            sample = sample.reshape(1, config.n_steps, len(config.feature_columns))  # Form anpassen\n",
    "            yield {'input_1': sample}\n",
    "\n",
    "def convert_model_to_tflite(keras_path, tflite_path, representative_dataset, config: LSTMConfig): \n",
    "    print(\"Creating temp SavedModel!\")\n",
    "    keras_model = tf.keras.models.load_model(keras_path)\n",
    "    keras_model.export(\"tmp\")\n",
    "    \n",
    "    print(\"Converting SavedModel to tflite!\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=\"tmp\")\n",
    "    converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS , tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.inference_output_type = tf.float32\n",
    "\n",
    "    # Wird benötigt für den Quantizierungs-Prozess\n",
    "    converter.representative_dataset = lambda: generate_representative_data(representative_dataset, config)\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "        \n",
    "    print(\"Removing temp SavedModel!\")\n",
    "    shutil.rmtree(\"tmp\")\n",
    "    print(\"Finished!\")"
   ],
   "id": "d5da6b15ac1ab32f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "639bc7eda3696212"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Datensatz\n",
    "\n",
    "### Es wird ein zufälliger Datensatz erzeugt"
   ],
   "id": "cbb86afd06a2533d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:17.299279Z",
     "start_time": "2024-10-28T12:45:17.294405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zufällige Datensätze erzeugen\n",
    "train_dates = pd.date_range(start='2020-01-01', periods=10000)\n",
    "pred_dates = pd.date_range(start='2021-01-01', periods=100)\n",
    "\n",
    "train_data = {\n",
    "    'feature1': np.random.rand(10000).astype(np.float32),\n",
    "    'feature2': np.random.rand(10000).astype(np.float32),\n",
    "    'feature3': np.random.rand(10000).astype(np.float32),\n",
    "    'label': np.random.rand(10000).astype(np.float32)\n",
    "}\n",
    "\n",
    "pred_data = {\n",
    "    'feature1': np.random.rand(100).astype(np.float32),\n",
    "    'feature2': np.random.rand(100).astype(np.float32),\n",
    "    'feature3': np.random.rand(100).astype(np.float32),\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(train_data, index=train_dates)\n",
    "df_pred = pd.DataFrame(pred_data, index=pred_dates)"
   ],
   "id": "742904d59b89a4bc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Initialisierung\n",
    "\n",
    "### Das Model wird mit gegebener Konfiguration initialisiert"
   ],
   "id": "6561d11ae654ea5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:46:17.967506Z",
     "start_time": "2024-10-28T12:46:17.847367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konfiguration erstellen und Modell instanziieren\n",
    "config = LSTMConfig(\n",
    "    feature_columns=['feature1', 'feature2', 'feature3'],\n",
    "    label_column='label',\n",
    "    scaled_labels=False,\n",
    "    n_steps=25,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "f89d0ab3c6eb02d1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trainings-Step",
   "id": "fc712c222bf5b4ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:46:29.654571Z",
     "start_time": "2024-10-28T12:46:20.602682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start des Trainings\n",
    "ts_lstm.train(dataframe=df_train)"
   ],
   "id": "34a68e059d933c63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s 6ms/step - loss: 0.0948\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0838\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0834\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0829\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0830\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0826\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0828\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0827\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0825\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0824\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Loss: 0.08252748101949692\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prediction Step",
   "id": "80a043aa621074c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:13:31.300816Z",
     "start_time": "2024-10-15T12:13:31.104657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modell Predictions erzeugen\n",
    "\n",
    "pred_results = ts_lstm.predict(df_pred)\n",
    "\n",
    "df_pred_no_time = pd.DataFrame(pred_data)\n",
    "for index, row in df_pred_no_time.iterrows():\n",
    "    if index < config.n_steps:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", \"Not enough data\")\n",
    "    else:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", pred_results[index-config.n_steps])"
   ],
   "id": "c7d7dcacae7fea46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "F: 0.51403713 0.19882914 0.5911012  P: Not enough data\n",
      "F: 0.11934123 0.40530437 0.89096767  P: Not enough data\n",
      "F: 0.38564697 0.29791084 0.19773565  P: Not enough data\n",
      "F: 0.6703891 0.71410924 0.5589309  P: Not enough data\n",
      "F: 0.6856324 0.26695275 0.604667  P: Not enough data\n",
      "F: 0.37407333 0.5748829 0.76460654  P: Not enough data\n",
      "F: 0.045838956 0.85503596 0.37089372  P: Not enough data\n",
      "F: 0.11443184 0.062243324 0.710078  P: Not enough data\n",
      "F: 0.35948795 0.42584494 0.7620492  P: Not enough data\n",
      "F: 0.5214783 0.36130518 0.88608074  P: Not enough data\n",
      "F: 0.9309409 0.4325166 0.7721853  P: Not enough data\n",
      "F: 0.5279233 0.8800477 0.5392751  P: Not enough data\n",
      "F: 0.33663088 0.6341414 0.3659117  P: Not enough data\n",
      "F: 0.8563349 0.4537363 0.38099846  P: Not enough data\n",
      "F: 0.7088956 0.10979994 0.4552031  P: Not enough data\n",
      "F: 0.42051426 0.9532006 0.94734293  P: Not enough data\n",
      "F: 0.62419176 0.5616601 0.22580338  P: Not enough data\n",
      "F: 0.19315931 0.49989152 0.94404525  P: Not enough data\n",
      "F: 0.13220085 0.38574183 0.85863066  P: Not enough data\n",
      "F: 0.48927695 0.560172 0.011551256  P: Not enough data\n",
      "F: 0.10607543 0.7570634 0.8861291  P: Not enough data\n",
      "F: 0.6636275 0.32873437 0.823422  P: Not enough data\n",
      "F: 0.08417101 0.9938953 0.8140583  P: Not enough data\n",
      "F: 0.7712223 0.6914217 0.5376309  P: Not enough data\n",
      "F: 0.28833458 0.406496 0.1978169  P: Not enough data\n",
      "F: 0.3983846 0.95207506 0.7505153  P: [0.4747945]\n",
      "F: 0.3946925 0.8963494 0.3028491  P: [0.47674352]\n",
      "F: 0.05294987 0.28149277 0.39824852  P: [0.4765578]\n",
      "F: 0.32014358 0.67472327 0.7792752  P: [0.47411436]\n",
      "F: 0.6616065 0.05735944 0.5675902  P: [0.47449017]\n",
      "F: 0.63627666 0.56664836 0.048654612  P: [0.48015147]\n",
      "F: 0.7836055 0.27310893 0.54620373  P: [0.48141724]\n",
      "F: 0.6484505 0.09207389 0.8531832  P: [0.48441964]\n",
      "F: 0.08989168 0.44443265 0.8396912  P: [0.48345304]\n",
      "F: 0.23692825 0.14912888 0.705546  P: [0.47215357]\n",
      "F: 0.25583413 0.16654022 0.43946144  P: [0.4717213]\n",
      "F: 0.90758824 0.054478835 0.55237436  P: [0.472692]\n",
      "F: 0.54202956 0.34710947 0.7996528  P: [0.4859445]\n",
      "F: 0.8535665 0.30902532 0.61588776  P: [0.47387305]\n",
      "F: 0.13289605 0.4401018 0.5260575  P: [0.48000765]\n",
      "F: 0.4949505 0.40676832 0.98499477  P: [0.47138277]\n",
      "F: 0.5682406 0.32822976 0.65451807  P: [0.47098333]\n",
      "F: 0.06937735 0.44287038 0.003226418  P: [0.47277576]\n",
      "F: 0.9737601 0.61246467 0.6494063  P: [0.4554853]\n",
      "F: 0.4491022 0.53566504 0.36772522  P: [0.4763246]\n",
      "F: 0.9589011 0.16532339 0.25872746  P: [0.47488588]\n",
      "F: 0.35778314 0.53696716 0.47385022  P: [0.48181242]\n",
      "F: 0.7914795 0.32677048 0.029292451  P: [0.47396198]\n",
      "F: 0.35182625 0.571196 0.27259728  P: [0.47975123]\n",
      "F: 0.65045106 0.5139587 0.87588966  P: [0.4820324]\n",
      "F: 0.23736574 0.19045915 0.10954196  P: [0.47940883]\n",
      "F: 0.26739395 0.011894234 0.9883093  P: [0.4783193]\n",
      "F: 0.6599377 0.07068916 0.8319202  P: [0.49350882]\n",
      "F: 0.28839165 0.8456586 0.6589199  P: [0.49697053]\n",
      "F: 0.3723383 0.60607576 0.69709474  P: [0.48417118]\n",
      "F: 0.96213895 0.66323584 0.39301363  P: [0.47717944]\n",
      "F: 0.97018456 0.52318275 0.12182373  P: [0.48492488]\n",
      "F: 0.6433087 0.7741509 0.5152273  P: [0.4877857]\n",
      "F: 0.5384767 0.08750506 0.22002523  P: [0.48532793]\n",
      "F: 0.8372823 0.37949324 0.72962517  P: [0.48379055]\n",
      "F: 0.8990525 0.22580017 0.18464856  P: [0.48306602]\n",
      "F: 0.38456175 0.42463702 0.82179976  P: [0.48359343]\n",
      "F: 0.22523522 0.33518478 0.3476741  P: [0.47506094]\n",
      "F: 0.27739954 0.22606632 0.6430577  P: [0.47542217]\n",
      "F: 0.53853005 0.11766241 0.062447235  P: [0.4764195]\n",
      "F: 0.8546604 0.32708746 0.31126377  P: [0.4810237]\n",
      "F: 0.8320798 0.5203937 0.23040089  P: [0.48700133]\n",
      "F: 0.7700596 0.37310278 0.22462413  P: [0.4888732]\n",
      "F: 0.8811286 0.33805534 0.3160066  P: [0.49077147]\n",
      "F: 0.39301956 0.94850457 0.78877866  P: [0.49121043]\n",
      "F: 0.9404266 0.2587561 0.7262606  P: [0.4834284]\n",
      "F: 0.86999303 0.16029647 0.9210936  P: [0.4847135]\n",
      "F: 0.95227265 0.8303039 0.57670903  P: [0.48483428]\n",
      "F: 0.90284497 0.55347264 0.037326545  P: [0.47911057]\n",
      "F: 0.009861089 0.09669762 0.56428945  P: [0.48392802]\n",
      "F: 0.1313332 0.5159357 0.18208331  P: [0.49755904]\n",
      "F: 0.98926836 0.866441 0.27117586  P: [0.48962212]\n",
      "F: 0.54463947 0.687957 0.46692324  P: [0.49957368]\n",
      "F: 0.33682856 0.118074484 0.91983795  P: [0.49695292]\n",
      "F: 0.3379626 0.06699804 0.35189778  P: [0.4903919]\n",
      "F: 0.102978736 0.20571272 0.7865161  P: [0.48796052]\n",
      "F: 0.036181226 0.2901685 0.8909183  P: [0.49159068]\n",
      "F: 0.13929659 0.38210917 0.20137511  P: [0.49886402]\n",
      "F: 0.6124165 0.46874627 0.69383776  P: [0.4895938]\n",
      "F: 0.16323213 0.8740749 0.5594947  P: [0.48631874]\n",
      "F: 0.66703963 0.66398436 0.7964448  P: [0.4803588]\n",
      "F: 0.5614926 0.9724125 0.02677405  P: [0.47407672]\n",
      "F: 0.2485148 0.4724953 0.4603526  P: [0.4737911]\n",
      "F: 0.67865247 0.60557866 0.13872944  P: [0.47456843]\n",
      "F: 0.79949206 0.414929 0.6851424  P: [0.4815458]\n",
      "F: 0.11192233 0.77361333 0.521974  P: [0.48248243]\n",
      "F: 0.8939152 0.5715325 0.108909816  P: [0.47286963]\n",
      "F: 0.39729017 0.73760843 0.35122886  P: [0.47731414]\n",
      "F: 0.5152495 0.06440042 0.17496228  P: [0.4808576]\n",
      "F: 0.53784806 0.47035545 0.9190049  P: [0.47928366]\n",
      "F: 0.27196544 0.09998814 0.23230983  P: [0.47511142]\n",
      "F: 0.37764835 0.9940766 0.46451226  P: [0.4732932]\n",
      "F: 0.44830796 0.6026568 0.09229851  P: [0.47669733]\n",
      "F: 0.36787257 0.8829762 0.49822736  P: [0.4812325]\n",
      "F: 0.8515667 0.2094194 0.81918967  P: [0.48210216]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modell Speichern, Laden und Konvertieren",
   "id": "62f4cc1909cebe6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:46:34.296229Z",
     "start_time": "2024-10-28T12:46:34.272034Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.save_model(\"TestModel.keras\")",
   "id": "209c16dc220efd3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:33.586577Z",
     "start_time": "2024-10-28T12:45:32.902839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lade das Modell aus der TF-Lite Datei\n",
    "ts_lstm.load_model(\"TestModel.keras\")"
   ],
   "id": "4830dba6364866cd",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 25, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_1'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/engine/base_layer.py:868\u001B[0m, in \u001B[0;36mLayer.from_config\u001B[0;34m(cls, config)\u001B[0m\n\u001B[1;32m    867\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 868\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/engine/input_layer.py:153\u001B[0m, in \u001B[0;36mInputLayer.__init__\u001B[0;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[0;32m--> 153\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    154\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized keyword arguments: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    155\u001B[0m     )\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sparse \u001B[38;5;129;01mand\u001B[39;00m ragged:\n",
      "\u001B[0;31mValueError\u001B[0m: Unrecognized keyword arguments: ['batch_shape']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Lade das Modell aus der TF-Lite Datei\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mts_lstm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTestModel.keras\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[2], line 39\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.load_model\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(\u001B[38;5;28mself\u001B[39m, path):\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel loaded!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/saving/saving_api.py:230\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[1;32m    226\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    227\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe following argument(s) are not supported \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    228\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith the native Keras format: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    229\u001B[0m         )\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msaving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43msafe_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m legacy_sm_saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    239\u001B[0m     filepath, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects, \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    240\u001B[0m )\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:275\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[1;32m    272\u001B[0m             asset_store\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 275\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:240\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# Construct the model from the configuration file in the archive.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ObjectSharingScope():\n\u001B[0;32m--> 240\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_mode\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m all_filenames \u001B[38;5;241m=\u001B[39m zf\u001B[38;5;241m.\u001B[39mnamelist()\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _VARS_FNAME \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m all_filenames:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:704\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(config, custom_objects, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    702\u001B[0m safe_mode_scope \u001B[38;5;241m=\u001B[39m SafeModeScope(safe_mode)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m custom_obj_scope, safe_mode_scope:\n\u001B[0;32m--> 704\u001B[0m     instance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43minner_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     build_config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbuild_config\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m build_config:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/engine/sequential.py:473\u001B[0m, in \u001B[0;36mSequential.from_config\u001B[0;34m(cls, config, custom_objects)\u001B[0m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer_config \u001B[38;5;129;01min\u001B[39;00m layer_configs:\n\u001B[1;32m    472\u001B[0m     use_legacy_format \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m layer_config\n\u001B[0;32m--> 473\u001B[0m     layer \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    475\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_legacy_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    478\u001B[0m     model\u001B[38;5;241m.\u001B[39madd(layer)\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    481\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m model\u001B[38;5;241m.\u001B[39minputs\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m build_input_shape\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(build_input_shape, (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m))\n\u001B[1;32m    484\u001B[0m ):\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/layers/serialization.py:276\u001B[0m, in \u001B[0;36mdeserialize\u001B[0;34m(config, custom_objects, use_legacy_format)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_legacy_format:\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m legacy_serialization\u001B[38;5;241m.\u001B[39mdeserialize_keras_object(\n\u001B[1;32m    270\u001B[0m         config,\n\u001B[1;32m    271\u001B[0m         module_objects\u001B[38;5;241m=\u001B[39mLOCAL\u001B[38;5;241m.\u001B[39mALL_OBJECTS,\n\u001B[1;32m    272\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    273\u001B[0m         printable_module_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    274\u001B[0m     )\n\u001B[0;32m--> 276\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mserialization_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mLOCAL\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL_OBJECTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlayer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:600\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(config, custom_objects, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(module_objects[config], types\u001B[38;5;241m.\u001B[39mFunctionType):\n\u001B[1;32m    594\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m deserialize_keras_object(\n\u001B[1;32m    595\u001B[0m                 serialize_with_public_fn(\n\u001B[1;32m    596\u001B[0m                     module_objects[config], config, fn_module_name\n\u001B[1;32m    597\u001B[0m                 ),\n\u001B[1;32m    598\u001B[0m                 custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    599\u001B[0m             )\n\u001B[0;32m--> 600\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[43m            \u001B[49m\u001B[43mserialize_with_public_class\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[43m[\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minner_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minner_config\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    605\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PLAIN_TYPES):\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m config\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:704\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(config, custom_objects, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    702\u001B[0m safe_mode_scope \u001B[38;5;241m=\u001B[39m SafeModeScope(safe_mode)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m custom_obj_scope, safe_mode_scope:\n\u001B[0;32m--> 704\u001B[0m     instance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43minner_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     build_config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbuild_config\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m build_config:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/keras/src/engine/base_layer.py:870\u001B[0m, in \u001B[0;36mLayer.from_config\u001B[0;34m(cls, config)\u001B[0m\n\u001B[1;32m    868\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig)\n\u001B[1;32m    869\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 870\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError when deserializing class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m using \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mException encountered: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    873\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 25, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_1'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:55:52.065541Z",
     "start_time": "2024-10-28T12:55:52.031363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ModelSpecificInfo(BaseModel):\n",
    "    name: str\n",
    "    version: int\n",
    "    num_inputs: int\n",
    "    num_outputs: int        \n",
    "\n",
    "\n",
    "_MODEL_INFO = ModelSpecificInfo(\n",
    "        name=\"Testmodell\",\n",
    "        version=1.0,\n",
    "        num_inputs=2,\n",
    "        num_outputs=1\n",
    ")\n",
    "\n",
    "\n",
    "def add_metadata_to_model(model_path: str, metadata: ModelSpecificInfo):\n",
    "    \n",
    "    model_meta = _metadata_fb.ModelMetadataT()\n",
    "    model_meta.name = metadata.name\n",
    "    model_meta.description = \"Ein tolles Modell\"\n",
    "    \n",
    "    input_meta = _metadata_fb.TensorMetadataT()\n",
    "    input_meta.name = \"Heart Rate\"\n",
    "    input_meta.description = \"Die Herzfrequenz halt...\"\n",
    "    input_meta.content = _metadata_fb.ContentT()\n",
    "    input_meta.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta.content.contentProperties.min = 50\n",
    "    input_meta.content.contentProperties.max = 150\n",
    "    \n",
    "    output_meta = _metadata_fb.TensorMetadataT()\n",
    "    output_meta.name = \"Probability\"\n",
    "    output_meta.description = \"Probabilities of the labels\"\n",
    "    \n",
    "    # Creates subgraph info.\n",
    "    subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "    subgraph.inputTensorMetadata = [input_meta]\n",
    "    subgraph.outputTensorMetadata = [output_meta]\n",
    "    model_meta.subgraphMetadata = [subgraph]\n",
    "    \n",
    "    b = flatbuffers.Builder(0)\n",
    "    b.Finish(\n",
    "        model_meta.Pack(b),\n",
    "        _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER\n",
    "    )\n",
    "    metadata_buffer = b.Output()\n",
    "    populator = _metadata.MetadataPopulator.with_model_file(model_path)\n",
    "    populator.load_metadata_buffer(metadata_buffer)\n",
    "    populator.populate()\n",
    "    \n",
    "\n",
    "# MinMax bezeichnet die Grenzen, auf die die Werte normalisiert wurden.\n",
    "metadata = {\n",
    "    'name': \"Testmodell\",\n",
    "    'type': \"Classification\",\n",
    "    'description': \"Ein Testmodell das nicht funktioniert.\",\n",
    "    'inputs': [\n",
    "        {\n",
    "            'idx': 0,\n",
    "            'name': \"Heart Rate\",\n",
    "            'min': 50,\n",
    "            'max': 150\n",
    "        },\n",
    "        {\n",
    "            'idx': 1,\n",
    "            'name': \"Movement\",\n",
    "            'min': 0.0,\n",
    "            'max': 1.0\n",
    "        }\n",
    "    ],\n",
    "    'outputs': [\n",
    "        {\n",
    "            'idx': 0,\n",
    "            'name': \"Sleep Label\",\n",
    "            'labels': [\n",
    "                {\n",
    "                    'name': \"Awake\",\n",
    "                    'threshold': 0.1,\n",
    "                },\n",
    "                {\n",
    "                    'name': \"Asleep\",\n",
    "                    'threshold': 0.5,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "add_metadata_to_model(\"TestModel.tflite\", _MODEL_INFO)"
   ],
   "id": "7d6b459aedcf33a3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:46:41.555304Z",
     "start_time": "2024-10-28T12:46:40.719934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konvertiere das Keras-Modell in ein tflite-Modell\n",
    "convert_model_to_tflite(\"TestModel.keras\", \"TestModel.tflite\", df_pred, config)"
   ],
   "id": "c5bcafd41e5d9483",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temp SavedModel!\n",
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'tmp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  Args:\n",
      "    args_0: float32 Tensor, shape=(None, 25, 3)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(None, 1)\n",
      "Converting SavedModel to tflite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 13:46:41.292862: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-10-28 13:46:41.292880: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-10-28 13:46:41.293101: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: tmp\n",
      "2024-10-28 13:46:41.293673: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-10-28 13:46:41.293683: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: tmp\n",
      "2024-10-28 13:46:41.295012: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-10-28 13:46:41.295485: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-10-28 13:46:41.318904: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: tmp\n",
      "2024-10-28 13:46:41.333493: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 40388 microseconds.\n",
      "2024-10-28 13:46:41.343372: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-28 13:46:41.382485: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<1x?x64xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "2024-10-28 13:46:41.385860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-28 13:46:41.385991: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 21 nodes with 2 partitions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp SavedModel!\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 13:46:41.449561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-28 13:46:41.449665: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:03:19.899068Z",
     "start_time": "2024-10-10T14:02:29.213983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "feature_columns = [\n",
    "    \"movementData\",\n",
    "    #\"sleepLevels\",\n",
    "    #\"restlessMoments\",\n",
    "    \"heartrate\",\n",
    "    #\"stress\",\n",
    "    #\"bodyBattery\",\n",
    "    #\"hrv\"\n",
    "]\n",
    "\n",
    "label_column = 'sleepLevels'\n",
    "\n",
    "config = LSTMConfig(\n",
    "    feature_columns=feature_columns,\n",
    "    label_column=label_column,\n",
    "    n_steps=50,\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    scaled_labels=True,\n",
    "    checkpoint_path=\"models/chkp.keras\")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)\n",
    "ts_lstm.train(dataframe=df_train[feature_columns + [label_column]])\n",
    "\n",
    "inputs = np.ones((1,50,2)) * 0.1\n",
    "\n",
    "print(\"Inputs:\", inputs, \"|\", \"Output:\", ts_lstm.predict(inputs))\n",
    "\n",
    "ts_lstm.save_tflite_model(\"models/tfLiteModel.tflite\", dataset=df_train[feature_columns])"
   ],
   "id": "df452a55c88e3f04",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21587/2948458530.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21587/2818307351.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y.append(labels[i + self.config.n_steps])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m743/744\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0316\n",
      "Epoch 1: saving model to models/chkp.keras\n",
      "\u001B[1m744/744\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 7ms/step - loss: 0.0316\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 0.0262\n",
      "Loss: 0.026939673349261284\n",
      "INFO:tensorflow:Assets written to: testModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testModel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'testModel/'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 2), dtype=tf.float32, name='input_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 50, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  130926510587072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926510587248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926510582496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926511002848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130926511003728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728568957.471736   21587 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1728568957.471755   21587 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-10-10 16:02:37.471911: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: testModel/\n",
      "2024-10-10 16:02:37.472380: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-10 16:02:37.472390: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: testModel/\n",
      "2024-10-10 16:02:37.476396: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-10 16:02:37.495943: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: testModel/\n",
      "2024-10-10 16:02:37.503940: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 32032 microseconds.\n",
      "2024-10-10 16:02:37.542021: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3463] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x50xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x50xf32>>>, tensor<i32>, tensor<?x50xf32>) -> (tensor<!tf_type.variant<tensor<?x50xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x50xf32>>>, tensor<2xi32>) -> (tensor<50x?x50xf32>) : {device = \"\", num_elements = 50 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "I0000 00:00:1728568957.545027   21587 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-10 16:02:37.545189: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-10-10 16:02:37.545632: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_inter_op_parallelism which is not in the op definition: Op<name=TensorListReserve; signature=element_shape:shape_type, num_elements:int32 -> handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node TensorListReserve}}\n",
      "I0000 00:00:1728568957.993692   21587 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-10 16:02:37.993866: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utils",
   "id": "ee35f19675a17710"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def list_all_files(path):\n",
    "    try:\n",
    "        files = []\n",
    "\n",
    "        for f in os.listdir(path):\n",
    "            filepath = os.path.join(path, f)\n",
    "            if os.path.isfile(filepath):  # Prüft, ob es sich um eine Datei handelt\n",
    "                files.append(f)\n",
    "\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Das Verzeichnis '{path}' wurde nicht gefunden.\")\n",
    "        return []"
   ],
   "id": "5f712c5337735a19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
