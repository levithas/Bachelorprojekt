{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T12:57:42.169776Z",
     "start_time": "2025-01-13T12:57:40.293271Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import flatbuffers\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Concatenate, Normalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support import metadata as _metadata"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 13:57:40.758469: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-13 13:57:40.760031: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-13 13:57:40.791870: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-13 13:57:40.792436: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-13 13:57:41.290029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:58:23.985764Z",
     "start_time": "2025-01-13T12:58:23.949411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMConfig(BaseModel):\n",
    "    feature_columns: list[str]\n",
    "    label_names: list[str]\n",
    "    label_count: int = Field(default=0)\n",
    "    scaled_labels: bool\n",
    "    n_steps: int = Field(default=50, ge=1)\n",
    "    batch_size: int = Field(default=32, ge=1)\n",
    "    epochs: int = Field(default=20, ge=1)\n",
    "    test_size: float = Field(default=0.2, ge=0, le=1)\n",
    "    checkpoint_path: str = Field(default=\"\")\n",
    "    loss_function: str\n",
    "\n",
    "\n",
    "class TimeSeriesLSTM:\n",
    "\n",
    "    def __init__(self, config: LSTMConfig):\n",
    "        self.config = config\n",
    "        self.model: Model = None\n",
    "\n",
    "    def _create_segments(self, data: pd.Series, n_steps):\n",
    "        num_samples = len(data) - n_steps + 1\n",
    "        return np.array([data[i:i + n_steps] for i in range(num_samples)]).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    def dataframe_to_pred_data(self, df_prediction: pd.DataFrame):\n",
    "        features = self.config.feature_columns\n",
    "        n_steps = self.config.n_steps\n",
    "        \n",
    "        X = []\n",
    "        # Create Time Series in Timestamp\n",
    "        segmented_data = self._create_segments(df_prediction.index.asi8, n_steps)\n",
    "        X.append(segmented_data[:, :, np.newaxis])\n",
    "        \n",
    "        for feature in features:\n",
    "            segmented_data = self._create_segments(df_prediction[feature], n_steps)\n",
    "            X.append(segmented_data[:, :, np.newaxis])\n",
    "        \n",
    "        return np.concatenate(X, axis=2)\n",
    "    \n",
    "\n",
    "    def dataframe_to_train_data(self, df_training: pd.DataFrame):\n",
    "        features = self.config.feature_columns\n",
    "        labels = self.config.label_names\n",
    "        n_steps = self.config.n_steps\n",
    "        \n",
    "        X = self.dataframe_to_pred_data(df_training[features])\n",
    "        \n",
    "        label_arrays = [self._create_segments(df_training[label], n_steps)[:, -1] for label in labels]\n",
    "        y = np.stack(label_arrays, axis=1)\n",
    "        \n",
    "        print(f\"Shape of X: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape}\")\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "        print(\"Model loaded!\")\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "    def build_model(self, adaptation_data):\n",
    "        inputs = []\n",
    "        lstm_outputs = []\n",
    "        \n",
    "        for feature_idx in range(len(self.config.feature_columns)+1):\n",
    "            if feature_idx > 0:\n",
    "                feature_name = self.config.feature_columns[feature_idx-1]\n",
    "            else:\n",
    "                feature_name = \"time\"\n",
    "            \n",
    "            input_tensor = Input(shape=(self.config.n_steps, 1), dtype=tf.float32, name=f'input_{feature_name}')\n",
    "            inputs.append(input_tensor)\n",
    "            normalization = Normalization()\n",
    "            normalization.adapt(adaptation_data.iloc[feature_idx])\n",
    "            lstm = LSTM(64, return_sequences=False, dtype=tf.float32)\n",
    "            lstm_outputs.append(lstm(normalization(input_tensor)))\n",
    "\n",
    "        merged = Concatenate(axis=1)(lstm_outputs)\n",
    "        \n",
    "        x = Dense(64, activation='relu')(merged)\n",
    "        if len(self.config.label_names) == 1:\n",
    "            output = Dense(self.config.label_count, activation='softmax')(x)\n",
    "        else:\n",
    "            output = Dense(len(self.config.label_names), activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=inputs, outputs=output)\n",
    "        self.model.compile(optimizer=Adam(), loss=self.config.loss_function, metrics=['accuracy'])\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def train(self, dataframe: pd.DataFrame):\n",
    "        X, y = self.dataframe_to_train_data(dataframe)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.config.test_size, random_state=69)\n",
    "        \n",
    "        X_train_split = np.split(X_train, indices_or_sections=3, axis=2)\n",
    "        X_test_split = np.split(X_test, indices_or_sections=3, axis=2)\n",
    "\n",
    "        X_train_squeeze = [arr.squeeze(axis=2) for arr in X_train_split]\n",
    "        X_test_squeeze = [arr.squeeze(axis=2) for arr in X_test_split]\n",
    "\n",
    "        self.model.fit(X_train_squeeze, y_train, epochs=self.config.epochs, batch_size=self.config.batch_size)\n",
    "        loss = self.model.evaluate(X_test_squeeze, y_test)\n",
    "        \n",
    "        print(f\"Loss: {loss}\")\n",
    "\n",
    "    def predict(self, input_data: pd.DataFrame):\n",
    "        X = self.dataframe_to_pred_data(input_data)       \n",
    "        X_split = np.split(X, indices_or_sections=3, axis=2)\n",
    "        X_squeeze = [arr.squeeze(axis=2) for arr in X_split]\n",
    "        return self.model.predict(X_squeeze)\n",
    "\n",
    "    def convert_to_tflite(self, tflite_path, representative_dataset):\n",
    "        print(\"Creating temp SavedModel\")\n",
    "        self.model.export(\"tmp\")\n",
    "        \n",
    "        print(\"Converting SavedModel to tflite\")\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=\"tmp\")\n",
    "        converter.optimizations = {tf.lite.Optimize.DEFAULT}\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS , tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "        converter.inference_input_type = tf.float32\n",
    "        converter.inference_output_type = tf.float32\n",
    "        \n",
    "        def representative_data_generator():\n",
    "            X = self.dataframe_to_pred_data(representative_dataset)\n",
    "            \n",
    "            for i, sample in enumerate(X):\n",
    "                sample = sample.reshape(1, self.config.n_steps, len(self.config.feature_columns)+1)\n",
    "                if i == 0:\n",
    "                    name = \"time\"\n",
    "                else:\n",
    "                    name = self.config.feature_columns[i-1]\n",
    "                yield {f'input_{name}': sample}\n",
    "        \n",
    "        def representative_data_generatorV2():\n",
    "            X = self.dataframe_to_pred_data(representative_dataset)\n",
    "            feature_count = len(self.config.feature_columns)+1\n",
    "            \n",
    "            for i, sample in enumerate(X):\n",
    "                reshaped_sample = sample.reshape(1, self.config.n_steps, feature_count)\n",
    "                sample_list = np.split(reshaped_sample, indices_or_sections=feature_count, axis=2)\n",
    "                yield sample_list\n",
    "        \n",
    "        converter.representative_dataset = lambda: representative_data_generatorV2()\n",
    "        \n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "            \n",
    "        print(\"Removing temp SavedModel\")\n",
    "        shutil.rmtree(\"tmp\")\n",
    "        print(\"Finished!\")\n"
   ],
   "id": "d5da6b15ac1ab32f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "639bc7eda3696212"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Datensatz\n",
    "\n",
    "### Es wird ein zufälliger Datensatz erzeugt"
   ],
   "id": "cbb86afd06a2533d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:21:15.636747Z",
     "start_time": "2024-12-20T12:21:15.627849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zufällige Datensätze erzeugen\n",
    "train_dates = pd.date_range(start='2020-01-01', periods=10000)\n",
    "pred_dates = pd.date_range(start='2021-01-01', periods=100)\n",
    "\n",
    "train_labels = np.random.randint(low=0, high=3, size=10000)\n",
    "\n",
    "train_data = {\n",
    "    'feature1': np.random.rand(10000).astype(np.float32),\n",
    "    'feature2': np.random.rand(10000).astype(np.float32),\n",
    "    'feature3': np.random.rand(10000).astype(np.float32),\n",
    "    'sleep': np.array([1 if lb == 0 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'awake': np.array([1 if lb == 1 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'rem': np.array([1 if lb == 2 else 0 for lb in train_labels]).astype(np.float32),\n",
    "    'light': np.array([1 if lb == 3 else 0 for lb in train_labels]).astype(np.float32)\n",
    "}\n",
    "\n",
    "pred_data = {\n",
    "    'feature1': np.random.rand(100).astype(np.float32),\n",
    "    'feature2': np.random.rand(100).astype(np.float32),\n",
    "    'feature3': np.random.rand(100).astype(np.float32),\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(train_data, index=train_dates)\n",
    "df_pred = pd.DataFrame(pred_data, index=pred_dates)"
   ],
   "id": "742904d59b89a4bc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Initialisierung\n",
    "\n",
    "### Das Model wird mit gegebener Konfiguration initialisiert"
   ],
   "id": "6561d11ae654ea5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:25:45.766856Z",
     "start_time": "2025-01-10T13:25:45.166190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konfiguration erstellen und Modell instanziieren\n",
    "config = LSTMConfig(\n",
    "    feature_columns=['time', 'movement', 'heartrate'],\n",
    "    label_names=['awake','lightSleep', 'asleep',  'REM'],\n",
    "    scaled_labels=False,\n",
    "    n_steps=25,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    loss_function=\"categorical_crossentropy\"\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "f89d0ab3c6eb02d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 14:25:45.335999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_time (InputLayer)     [(None, 25, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " input_movement (InputLayer  [(None, 25, 1)]              0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_heartrate (InputLaye  [(None, 25, 1)]              0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 64)                   16896     ['input_time[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 64)                   16896     ['input_movement[0][0]']      \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 64)                   16896     ['input_heartrate[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 192)                  0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   12352     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    65        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63105 (246.50 KB)\n",
      "Trainable params: 63105 (246.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trainings-Step",
   "id": "fc712c222bf5b4ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T12:23:50.504600Z",
     "start_time": "2024-12-20T12:23:19.266398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start des Trainings\n",
    "ts_lstm.train(dataframe=df_train)"
   ],
   "id": "34a68e059d933c63",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTMConfig' object has no attribute 'label_column'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Start des Trainings\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mts_lstm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[24], line 65\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.train\u001B[0;34m(self, dataframe)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataframe: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[0;32m---> 65\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m     X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtest_size, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m69\u001B[39m)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mepochs, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size)\n",
      "Cell \u001B[0;32mIn[24], line 26\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.preprocess_data\u001B[0;34m(self, dataframe, train_data)\u001B[0m\n\u001B[1;32m     24\u001B[0m         labels \u001B[38;5;241m=\u001B[39m dataframe[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlabel_column] \u001B[38;5;241m/\u001B[39m dataframe[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlabel_column]\u001B[38;5;241m.\u001B[39mmax()\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 26\u001B[0m         labels \u001B[38;5;241m=\u001B[39m dataframe[\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_column\u001B[49m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     28\u001B[0m X, y \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(scaled_data) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mn_steps):\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/pydantic/main.py:856\u001B[0m, in \u001B[0;36mBaseModel.__getattr__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(item)  \u001B[38;5;66;03m# Raises AttributeError if appropriate\u001B[39;00m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[0;32m--> 856\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LSTMConfig' object has no attribute 'label_column'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prediction Step",
   "id": "80a043aa621074c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T12:13:31.300816Z",
     "start_time": "2024-10-15T12:13:31.104657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modell Predictions erzeugen\n",
    "\n",
    "pred_results = ts_lstm.predict(df_pred)\n",
    "\n",
    "df_pred_no_time = pd.DataFrame(pred_data)\n",
    "for index, row in df_pred_no_time.iterrows():\n",
    "    if index < config.n_steps:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", \"Not enough data\")\n",
    "    else:\n",
    "        print(\"F:\", row['feature1'], row['feature2'], row['feature3'], \" P:\", pred_results[index-config.n_steps])"
   ],
   "id": "c7d7dcacae7fea46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "F: 0.51403713 0.19882914 0.5911012  P: Not enough data\n",
      "F: 0.11934123 0.40530437 0.89096767  P: Not enough data\n",
      "F: 0.38564697 0.29791084 0.19773565  P: Not enough data\n",
      "F: 0.6703891 0.71410924 0.5589309  P: Not enough data\n",
      "F: 0.6856324 0.26695275 0.604667  P: Not enough data\n",
      "F: 0.37407333 0.5748829 0.76460654  P: Not enough data\n",
      "F: 0.045838956 0.85503596 0.37089372  P: Not enough data\n",
      "F: 0.11443184 0.062243324 0.710078  P: Not enough data\n",
      "F: 0.35948795 0.42584494 0.7620492  P: Not enough data\n",
      "F: 0.5214783 0.36130518 0.88608074  P: Not enough data\n",
      "F: 0.9309409 0.4325166 0.7721853  P: Not enough data\n",
      "F: 0.5279233 0.8800477 0.5392751  P: Not enough data\n",
      "F: 0.33663088 0.6341414 0.3659117  P: Not enough data\n",
      "F: 0.8563349 0.4537363 0.38099846  P: Not enough data\n",
      "F: 0.7088956 0.10979994 0.4552031  P: Not enough data\n",
      "F: 0.42051426 0.9532006 0.94734293  P: Not enough data\n",
      "F: 0.62419176 0.5616601 0.22580338  P: Not enough data\n",
      "F: 0.19315931 0.49989152 0.94404525  P: Not enough data\n",
      "F: 0.13220085 0.38574183 0.85863066  P: Not enough data\n",
      "F: 0.48927695 0.560172 0.011551256  P: Not enough data\n",
      "F: 0.10607543 0.7570634 0.8861291  P: Not enough data\n",
      "F: 0.6636275 0.32873437 0.823422  P: Not enough data\n",
      "F: 0.08417101 0.9938953 0.8140583  P: Not enough data\n",
      "F: 0.7712223 0.6914217 0.5376309  P: Not enough data\n",
      "F: 0.28833458 0.406496 0.1978169  P: Not enough data\n",
      "F: 0.3983846 0.95207506 0.7505153  P: [0.4747945]\n",
      "F: 0.3946925 0.8963494 0.3028491  P: [0.47674352]\n",
      "F: 0.05294987 0.28149277 0.39824852  P: [0.4765578]\n",
      "F: 0.32014358 0.67472327 0.7792752  P: [0.47411436]\n",
      "F: 0.6616065 0.05735944 0.5675902  P: [0.47449017]\n",
      "F: 0.63627666 0.56664836 0.048654612  P: [0.48015147]\n",
      "F: 0.7836055 0.27310893 0.54620373  P: [0.48141724]\n",
      "F: 0.6484505 0.09207389 0.8531832  P: [0.48441964]\n",
      "F: 0.08989168 0.44443265 0.8396912  P: [0.48345304]\n",
      "F: 0.23692825 0.14912888 0.705546  P: [0.47215357]\n",
      "F: 0.25583413 0.16654022 0.43946144  P: [0.4717213]\n",
      "F: 0.90758824 0.054478835 0.55237436  P: [0.472692]\n",
      "F: 0.54202956 0.34710947 0.7996528  P: [0.4859445]\n",
      "F: 0.8535665 0.30902532 0.61588776  P: [0.47387305]\n",
      "F: 0.13289605 0.4401018 0.5260575  P: [0.48000765]\n",
      "F: 0.4949505 0.40676832 0.98499477  P: [0.47138277]\n",
      "F: 0.5682406 0.32822976 0.65451807  P: [0.47098333]\n",
      "F: 0.06937735 0.44287038 0.003226418  P: [0.47277576]\n",
      "F: 0.9737601 0.61246467 0.6494063  P: [0.4554853]\n",
      "F: 0.4491022 0.53566504 0.36772522  P: [0.4763246]\n",
      "F: 0.9589011 0.16532339 0.25872746  P: [0.47488588]\n",
      "F: 0.35778314 0.53696716 0.47385022  P: [0.48181242]\n",
      "F: 0.7914795 0.32677048 0.029292451  P: [0.47396198]\n",
      "F: 0.35182625 0.571196 0.27259728  P: [0.47975123]\n",
      "F: 0.65045106 0.5139587 0.87588966  P: [0.4820324]\n",
      "F: 0.23736574 0.19045915 0.10954196  P: [0.47940883]\n",
      "F: 0.26739395 0.011894234 0.9883093  P: [0.4783193]\n",
      "F: 0.6599377 0.07068916 0.8319202  P: [0.49350882]\n",
      "F: 0.28839165 0.8456586 0.6589199  P: [0.49697053]\n",
      "F: 0.3723383 0.60607576 0.69709474  P: [0.48417118]\n",
      "F: 0.96213895 0.66323584 0.39301363  P: [0.47717944]\n",
      "F: 0.97018456 0.52318275 0.12182373  P: [0.48492488]\n",
      "F: 0.6433087 0.7741509 0.5152273  P: [0.4877857]\n",
      "F: 0.5384767 0.08750506 0.22002523  P: [0.48532793]\n",
      "F: 0.8372823 0.37949324 0.72962517  P: [0.48379055]\n",
      "F: 0.8990525 0.22580017 0.18464856  P: [0.48306602]\n",
      "F: 0.38456175 0.42463702 0.82179976  P: [0.48359343]\n",
      "F: 0.22523522 0.33518478 0.3476741  P: [0.47506094]\n",
      "F: 0.27739954 0.22606632 0.6430577  P: [0.47542217]\n",
      "F: 0.53853005 0.11766241 0.062447235  P: [0.4764195]\n",
      "F: 0.8546604 0.32708746 0.31126377  P: [0.4810237]\n",
      "F: 0.8320798 0.5203937 0.23040089  P: [0.48700133]\n",
      "F: 0.7700596 0.37310278 0.22462413  P: [0.4888732]\n",
      "F: 0.8811286 0.33805534 0.3160066  P: [0.49077147]\n",
      "F: 0.39301956 0.94850457 0.78877866  P: [0.49121043]\n",
      "F: 0.9404266 0.2587561 0.7262606  P: [0.4834284]\n",
      "F: 0.86999303 0.16029647 0.9210936  P: [0.4847135]\n",
      "F: 0.95227265 0.8303039 0.57670903  P: [0.48483428]\n",
      "F: 0.90284497 0.55347264 0.037326545  P: [0.47911057]\n",
      "F: 0.009861089 0.09669762 0.56428945  P: [0.48392802]\n",
      "F: 0.1313332 0.5159357 0.18208331  P: [0.49755904]\n",
      "F: 0.98926836 0.866441 0.27117586  P: [0.48962212]\n",
      "F: 0.54463947 0.687957 0.46692324  P: [0.49957368]\n",
      "F: 0.33682856 0.118074484 0.91983795  P: [0.49695292]\n",
      "F: 0.3379626 0.06699804 0.35189778  P: [0.4903919]\n",
      "F: 0.102978736 0.20571272 0.7865161  P: [0.48796052]\n",
      "F: 0.036181226 0.2901685 0.8909183  P: [0.49159068]\n",
      "F: 0.13929659 0.38210917 0.20137511  P: [0.49886402]\n",
      "F: 0.6124165 0.46874627 0.69383776  P: [0.4895938]\n",
      "F: 0.16323213 0.8740749 0.5594947  P: [0.48631874]\n",
      "F: 0.66703963 0.66398436 0.7964448  P: [0.4803588]\n",
      "F: 0.5614926 0.9724125 0.02677405  P: [0.47407672]\n",
      "F: 0.2485148 0.4724953 0.4603526  P: [0.4737911]\n",
      "F: 0.67865247 0.60557866 0.13872944  P: [0.47456843]\n",
      "F: 0.79949206 0.414929 0.6851424  P: [0.4815458]\n",
      "F: 0.11192233 0.77361333 0.521974  P: [0.48248243]\n",
      "F: 0.8939152 0.5715325 0.108909816  P: [0.47286963]\n",
      "F: 0.39729017 0.73760843 0.35122886  P: [0.47731414]\n",
      "F: 0.5152495 0.06440042 0.17496228  P: [0.4808576]\n",
      "F: 0.53784806 0.47035545 0.9190049  P: [0.47928366]\n",
      "F: 0.27196544 0.09998814 0.23230983  P: [0.47511142]\n",
      "F: 0.37764835 0.9940766 0.46451226  P: [0.4732932]\n",
      "F: 0.44830796 0.6026568 0.09229851  P: [0.47669733]\n",
      "F: 0.36787257 0.8829762 0.49822736  P: [0.4812325]\n",
      "F: 0.8515667 0.2094194 0.81918967  P: [0.48210216]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modell Speichern, Laden und Konvertieren",
   "id": "62f4cc1909cebe6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:20:35.348596Z",
     "start_time": "2024-12-17T17:20:35.320025Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.save_model(\"TestModel.keras\")",
   "id": "209c16dc220efd3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:33:31.855675Z",
     "start_time": "2024-12-17T17:33:31.697605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lade das Modell aus der TF-Lite Datei\n",
    "ts_lstm.load_model(\"TestModel.keras\")"
   ],
   "id": "4830dba6364866cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:37:10.832888Z",
     "start_time": "2024-12-17T17:37:10.785422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ModelSpecificInfo(BaseModel):\n",
    "    name: str\n",
    "    version: float\n",
    "    num_inputs: int\n",
    "    num_outputs: int        \n",
    "\n",
    "\n",
    "_MODEL_INFO = ModelSpecificInfo(\n",
    "        name=\"Testmodell\",\n",
    "        version=1.0,\n",
    "        num_inputs=3,\n",
    "        num_outputs=2\n",
    ")\n",
    "\n",
    "\n",
    "def add_metadata_to_model(model_path: str, metadata: ModelSpecificInfo):\n",
    "    \n",
    "    model_meta = _metadata_fb.ModelMetadataT()\n",
    "    model_meta.name = metadata.name\n",
    "    model_meta.description = \"Ein zufälliges Modell\"\n",
    "    \n",
    "    input_meta_0 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_0.name = \"Time\"\n",
    "    input_meta_0.dimensionNames = ['sin', 'cos']\n",
    "    input_meta_0.description = \"Die Tageszeit an dem der Wert aufgenommen wurde\"\n",
    "    input_meta_0.content = _metadata_fb.ContentT()\n",
    "    input_meta_0.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_0.content.contentProperties.min = 0\n",
    "    input_meta_0.content.contentProperties.max = 10\n",
    "    \n",
    "    input_meta_1 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_1.name = \"Movement\"\n",
    "    input_meta_1.description = \"Die Bewegungsintensität gemittelt aus den Beschleunigungssensoren\"\n",
    "    input_meta_1.content = _metadata_fb.ContentT()\n",
    "    input_meta_1.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_1.content.contentProperties.min = 0\n",
    "    input_meta_1.content.contentProperties.max = 1\n",
    "    \n",
    "    input_meta_2 = _metadata_fb.TensorMetadataT()\n",
    "    input_meta_2.name = \"Heartrate\"\n",
    "    input_meta_2.description = \"Die Anzahl an Herzschlägen pro Minute\"\n",
    "    input_meta_2.content = _metadata_fb.ContentT()\n",
    "    input_meta_2.content.contentProperties = _metadata_fb.ValueRangeT()\n",
    "    input_meta_2.content.contentProperties.min = 0\n",
    "    input_meta_2.content.contentProperties.max = 1\n",
    "    \n",
    "    output_meta_1 = _metadata_fb.TensorMetadataT()\n",
    "    output_meta_1.name = \"Sleeplabel\"\n",
    "    output_meta_1.description = \"Die aktuelle Schlafphase\"\n",
    "    \n",
    "\n",
    "    # Creates subgraph info.\n",
    "    subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "    subgraph.inputTensorMetadata = [input_meta_0, input_meta_1,input_meta_2]\n",
    "    subgraph.outputTensorMetadata = [output_meta_1]\n",
    "    model_meta.subgraphMetadata = [subgraph]\n",
    "    \n",
    "    b = flatbuffers.Builder(0)\n",
    "    \n",
    "    packed = model_meta.Pack(b)\n",
    "    \n",
    "    b.Finish(\n",
    "        packed,\n",
    "        _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER\n",
    "    )\n",
    "    metadata_buffer = b.Output()\n",
    "    populator = _metadata.MetadataPopulator.with_model_file(model_path)\n",
    "    populator.load_metadata_buffer(metadata_buffer)\n",
    "    populator.populate()\n",
    "    \n",
    "add_metadata_to_model(\"TestModel.tflite\", _MODEL_INFO)"
   ],
   "id": "7d6b459aedcf33a3",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of input tensors (1) should match the number of input tensor metadata (3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 69\u001B[0m\n\u001B[1;32m     66\u001B[0m     populator\u001B[38;5;241m.\u001B[39mload_metadata_buffer(metadata_buffer)\n\u001B[1;32m     67\u001B[0m     populator\u001B[38;5;241m.\u001B[39mpopulate()\n\u001B[0;32m---> 69\u001B[0m \u001B[43madd_metadata_to_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTestModel.tflite\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_MODEL_INFO\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[26], line 66\u001B[0m, in \u001B[0;36madd_metadata_to_model\u001B[0;34m(model_path, metadata)\u001B[0m\n\u001B[1;32m     64\u001B[0m metadata_buffer \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mOutput()\n\u001B[1;32m     65\u001B[0m populator \u001B[38;5;241m=\u001B[39m _metadata\u001B[38;5;241m.\u001B[39mMetadataPopulator\u001B[38;5;241m.\u001B[39mwith_model_file(model_path)\n\u001B[0;32m---> 66\u001B[0m \u001B[43mpopulator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_metadata_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetadata_buffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m populator\u001B[38;5;241m.\u001B[39mpopulate()\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow_lite_support/metadata/python/metadata.py:302\u001B[0m, in \u001B[0;36mMetadataPopulator.load_metadata_buffer\u001B[0;34m(self, metadata_buf)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m metadata_buf:\n\u001B[1;32m    300\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe metadata to be populated is empty.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetadata_buf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;66;03m# Gets the minimum metadata parser version of the metadata_buf.\u001B[39;00m\n\u001B[1;32m    305\u001B[0m min_version \u001B[38;5;241m=\u001B[39m _pywrap_metadata_version\u001B[38;5;241m.\u001B[39mGetMinimumMetadataParserVersion(\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28mbytes\u001B[39m(metadata_buf))\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow_lite_support/metadata/python/metadata.py:631\u001B[0m, in \u001B[0;36mMetadataPopulator._validate_metadata\u001B[0;34m(self, metadata_buf)\u001B[0m\n\u001B[1;32m    629\u001B[0m num_input_meta \u001B[38;5;241m=\u001B[39m model_meta\u001B[38;5;241m.\u001B[39mSubgraphMetadata(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mInputTensorMetadataLength()\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_input_tensors \u001B[38;5;241m!=\u001B[39m num_input_meta:\n\u001B[0;32m--> 631\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    632\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of input tensors (\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m) should match the number of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    633\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput tensor metadata (\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(num_input_tensors,\n\u001B[1;32m    634\u001B[0m                                            num_input_meta))\n\u001B[1;32m    635\u001B[0m num_output_tensors \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mSubgraphs(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mOutputsLength()\n\u001B[1;32m    636\u001B[0m num_output_meta \u001B[38;5;241m=\u001B[39m model_meta\u001B[38;5;241m.\u001B[39mSubgraphMetadata(\n\u001B[1;32m    637\u001B[0m     \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mOutputTensorMetadataLength()\n",
      "\u001B[0;31mValueError\u001B[0m: The number of input tensors (1) should match the number of input tensor metadata (3)"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:58:46.858796Z",
     "start_time": "2025-01-13T12:58:46.133149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n",
    "df_train = df_train.dropna()"
   ],
   "id": "45fa4297140dcc5c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68465/2381353175.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/2024-08-21.json\", dtype=np.float32)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sparse Categorical Crossentropy",
   "id": "2ad57f47c14dd2a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:58:34.423460Z",
     "start_time": "2025-01-13T12:58:34.420805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_columns = [\n",
    "    \"movementData\",\n",
    "    #\"sleepLevels\",\n",
    "    #\"restlessMoments\",\n",
    "    \"heartrate\",\n",
    "    #\"stress\",\n",
    "    #\"bodyBattery\",\n",
    "    #\"hrv\"\n",
    "]\n",
    "\n",
    "label_names = [\"sleepLevels\"]\n",
    "\n",
    "config = LSTMConfig(\n",
    "    feature_columns=feature_columns,\n",
    "    label_names=label_names,\n",
    "    label_count=4,\n",
    "    n_steps=120,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    scaled_labels=True,\n",
    "    checkpoint_path=\"models/chkp.keras\",\n",
    "    loss_function=\"sparse_categorical_crossentropy\"\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "5d0c8ae91df30008",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Categorical Crossentropy",
   "id": "d5e6b2af560f8665"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:32:06.646589Z",
     "start_time": "2025-01-13T10:32:06.621852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train['awake'] = [1 if d == 0 else 0 for d in df_train['sleepLevels']]\n",
    "df_train['asleep'] = [1 if d == 1 else 0 for d in df_train['sleepLevels']]\n",
    "df_train['lightSleep'] = [1 if d == 2 else 0 for d in df_train['sleepLevels']]\n",
    "df_train['rem'] = [1 if d == 3 else 0 for d in df_train['sleepLevels']]\n",
    "\n",
    "feature_columns = [\n",
    "    \"movementData\",\n",
    "    #\"sleepLevels\",\n",
    "    #\"restlessMoments\",\n",
    "    \"heartrate\",\n",
    "    #\"stress\",\n",
    "    #\"bodyBattery\",\n",
    "    #\"hrv\"\n",
    "]\n",
    "\n",
    "label_names = [\"awake\", \"lightSleep\", \"asleep\", \"rem\"]\n",
    "\n",
    "config = LSTMConfig(\n",
    "    feature_columns=feature_columns,\n",
    "    label_names=label_names,\n",
    "    n_steps=120,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    scaled_labels=True,\n",
    "    checkpoint_path=\"models/chkp.keras\",\n",
    "    loss_function=\"categorical_crossentropy\"\n",
    ")\n",
    "ts_lstm = TimeSeriesLSTM(config=config)"
   ],
   "id": "7430b0e1bcd8b35a",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Initialisation",
   "id": "c3a32698eef8a732"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:05:03.746263Z",
     "start_time": "2025-01-13T12:58:50.327004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts_lstm.build_model(df_train[feature_columns])\n",
    "ts_lstm.train(dataframe=df_train[feature_columns + label_names])\n",
    "print(\"Initial Training Completed!\")\n",
    "\n",
    "ts_lstm.convert_to_tflite(\"models/sleepPhaseAnalyserV1.tflite\", df_train)"
   ],
   "id": "1eec50bc72897ded",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 13:58:50.463254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-13 13:58:50.463636: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_time (InputLayer)     [(None, 120, 1)]             0         []                            \n",
      "                                                                                                  \n",
      " input_movementData (InputL  [(None, 120, 1)]             0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " input_heartrate (InputLaye  [(None, 120, 1)]             0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " normalization (Normalizati  (None, 120, 1)               3         ['input_time[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " normalization_1 (Normaliza  (None, 120, 1)               3         ['input_movementData[0][0]']  \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " normalization_2 (Normaliza  (None, 120, 1)               3         ['input_heartrate[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 64)                   16896     ['normalization[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 64)                   16896     ['normalization_1[0][0]']     \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 64)                   16896     ['normalization_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 192)                  0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   12352     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    260       ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63309 (247.31 KB)\n",
      "Trainable params: 63300 (247.27 KB)\n",
      "Non-trainable params: 9 (48.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Shape of X: (29674, 120, 3)\n",
      "Shape of y: (29674, 1)\n",
      "Epoch 1/2\n",
      "742/742 [==============================] - 22s 27ms/step - loss: 0.6549 - accuracy: 0.8167\n",
      "Epoch 2/2\n",
      "742/742 [==============================] - 21s 28ms/step - loss: 0.6311 - accuracy: 0.8204\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.5762 - accuracy: 0.8339\n",
      "Loss: [0.576157808303833, 0.8338668942451477]\n",
      "Initial Training Completed!\n",
      "Creating temp SavedModel\n",
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'tmp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  Args:\n",
      "    args_0: [<1>, <2>, <3>]\n",
      "      <1>: float32 Tensor, shape=(None, 120, 1)\n",
      "      <2>: float32 Tensor, shape=(None, 120, 1)\n",
      "      <3>: float32 Tensor, shape=(None, 120, 1)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(None, 4)\n",
      "Converting SavedModel to tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 13:59:41.631150: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-01-13 13:59:41.631172: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-01-13 13:59:41.631455: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: tmp\n",
      "2025-01-13 13:59:41.633815: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-01-13 13:59:41.633831: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: tmp\n",
      "2025-01-13 13:59:41.638818: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2025-01-13 13:59:41.640213: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-01-13 13:59:41.706766: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: tmp\n",
      "2025-01-13 13:59:41.748571: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 117115 microseconds.\n",
      "2025-01-13 13:59:41.771511: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-13 13:59:41.863812: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<1x?x64xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "2025-01-13 13:59:41.870096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-13 13:59:41.870226: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO: TfLiteFlexDelegate delegate: 4 nodes delegated out of 35 nodes with 2 partitions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp SavedModel\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:43:54.800055Z",
     "start_time": "2025-01-10T15:43:54.222256Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.load_model(\"models/sleepPhaseAnalyserV1.keras\")",
   "id": "9b5d72eed4aaf897",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:23:50.782163Z",
     "start_time": "2025-01-13T11:23:50.720089Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.save_model(\"models/sleepPhaseAnalyserV1.keras\")",
   "id": "df452a55c88e3f04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:37:30.912505Z",
     "start_time": "2025-01-13T11:37:26.801825Z"
    }
   },
   "cell_type": "code",
   "source": "ts_lstm.convert_to_tflite(\"models/sleepPhaseAnalyserV1.tflite\", df_train)",
   "id": "5858cd8cd2ffb018",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temp SavedModel\n",
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'tmp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  Args:\n",
      "    args_0: [<1>, <2>, <3>]\n",
      "      <1>: float32 Tensor, shape=(None, 120, 1)\n",
      "      <2>: float32 Tensor, shape=(None, 120, 1)\n",
      "      <3>: float32 Tensor, shape=(None, 120, 1)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(None, 4)\n",
      "Converting SavedModel to tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 12:37:28.019413: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-01-13 12:37:28.019443: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-01-13 12:37:28.019587: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: tmp\n",
      "2025-01-13 12:37:28.021147: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-01-13 12:37:28.021160: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: tmp\n",
      "2025-01-13 12:37:28.025278: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-01-13 12:37:28.081988: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: tmp\n",
      "2025-01-13 12:37:28.120295: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 100707 microseconds.\n",
      "2025-01-13 12:37:28.220775: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<1x?x64xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 360 into shape (1,120,2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mts_lstm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tflite\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodels/sleepPhaseAnalyserV1.tflite\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[46], line 134\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.convert_to_tflite\u001B[0;34m(self, tflite_path, representative_dataset)\u001B[0m\n\u001B[1;32m    130\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m {\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mfeature_columns[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m: sample}\n\u001B[1;32m    132\u001B[0m converter\u001B[38;5;241m.\u001B[39mrepresentative_dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m: representative_data_generator()\n\u001B[0;32m--> 134\u001B[0m tflite_model \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(tflite_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m    136\u001B[0m     f\u001B[38;5;241m.\u001B[39mwrite(tflite_model)\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1065\u001B[0m, in \u001B[0;36m_export_metrics.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(convert_func)\n\u001B[1;32m   1063\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1064\u001B[0m   \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m-> 1065\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_and_export_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1042\u001B[0m, in \u001B[0;36mTFLiteConverterBase._convert_and_export_metrics\u001B[0;34m(self, convert_func, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_conversion_params_metric()\n\u001B[1;32m   1041\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mprocess_time()\n\u001B[0;32m-> 1042\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1043\u001B[0m elapsed_time_ms \u001B[38;5;241m=\u001B[39m (time\u001B[38;5;241m.\u001B[39mprocess_time() \u001B[38;5;241m-\u001B[39m start_time) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[1;32m   1044\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1390\u001B[0m, in \u001B[0;36mTFLiteSavedModelConverterV2.convert\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1385\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_debug_info \u001B[38;5;241m=\u001B[39m _get_debug_info(\n\u001B[1;32m   1386\u001B[0m       _convert_debug_info_func(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trackable_obj\u001B[38;5;241m.\u001B[39mgraph_debug_info),\n\u001B[1;32m   1387\u001B[0m       graph_def,\n\u001B[1;32m   1388\u001B[0m   )\n\u001B[0;32m-> 1390\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_from_saved_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph_def\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1257\u001B[0m, in \u001B[0;36mTFLiteConverterBaseV2._convert_from_saved_model\u001B[0;34m(self, graph_def)\u001B[0m\n\u001B[1;32m   1254\u001B[0m converter_kwargs\u001B[38;5;241m.\u001B[39mupdate(quant_mode\u001B[38;5;241m.\u001B[39mconverter_flags())\n\u001B[1;32m   1256\u001B[0m result \u001B[38;5;241m=\u001B[39m _convert_saved_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconverter_kwargs)\n\u001B[0;32m-> 1257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimize_tflite_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_io\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexperimental_new_quantizer\u001B[49m\n\u001B[1;32m   1259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:215\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    214\u001B[0m   report_error_message(\u001B[38;5;28mstr\u001B[39m(error))\n\u001B[0;32m--> 215\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m error \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m ConverterError \u001B[38;5;28;01mas\u001B[39;00m converter_error:\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter_error\u001B[38;5;241m.\u001B[39merrors:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:991\u001B[0m, in \u001B[0;36mTFLiteConverterBase._optimize_tflite_model\u001B[0;34m(self, model, quant_mode, quant_io)\u001B[0m\n\u001B[1;32m    989\u001B[0m   q_allow_float \u001B[38;5;241m=\u001B[39m quant_mode\u001B[38;5;241m.\u001B[39mis_allow_float()\n\u001B[1;32m    990\u001B[0m   q_variable_quantization \u001B[38;5;241m=\u001B[39m quant_mode\u001B[38;5;241m.\u001B[39menable_mlir_variable_quantization\n\u001B[0;32m--> 991\u001B[0m   model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_quantize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    992\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    993\u001B[0m \u001B[43m      \u001B[49m\u001B[43mq_in_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    994\u001B[0m \u001B[43m      \u001B[49m\u001B[43mq_out_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    995\u001B[0m \u001B[43m      \u001B[49m\u001B[43mq_activations_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    996\u001B[0m \u001B[43m      \u001B[49m\u001B[43mq_bias_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    997\u001B[0m \u001B[43m      \u001B[49m\u001B[43mq_allow_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    998\u001B[0m \u001B[43m      \u001B[49m\u001B[43mq_variable_quantization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m m_in_type \u001B[38;5;241m=\u001B[39m in_type \u001B[38;5;28;01mif\u001B[39;00m in_type \u001B[38;5;28;01melse\u001B[39;00m _dtypes\u001B[38;5;241m.\u001B[39mfloat32\n\u001B[1;32m   1002\u001B[0m m_out_type \u001B[38;5;241m=\u001B[39m out_type \u001B[38;5;28;01mif\u001B[39;00m out_type \u001B[38;5;28;01melse\u001B[39;00m _dtypes\u001B[38;5;241m.\u001B[39mfloat32\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:710\u001B[0m, in \u001B[0;36mTFLiteConverterBase._quantize\u001B[0;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float, enable_variable_quantization)\u001B[0m\n\u001B[1;32m    706\u001B[0m calibrate_quantize \u001B[38;5;241m=\u001B[39m _calibrator\u001B[38;5;241m.\u001B[39mCalibrator(\n\u001B[1;32m    707\u001B[0m     result, custom_op_registerers_by_name, custom_op_registerers_by_func\n\u001B[1;32m    708\u001B[0m )\n\u001B[1;32m    709\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experimental_calibrate_only \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_new_quantizer:\n\u001B[0;32m--> 710\u001B[0m   calibrated \u001B[38;5;241m=\u001B[39m \u001B[43mcalibrate_quantize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalibrate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepresentative_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_gen\u001B[49m\n\u001B[1;32m    712\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experimental_calibrate_only:\n\u001B[1;32m    715\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m calibrated\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:215\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    214\u001B[0m   report_error_message(\u001B[38;5;28mstr\u001B[39m(error))\n\u001B[0;32m--> 215\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m error \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m ConverterError \u001B[38;5;28;01mas\u001B[39;00m converter_error:\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter_error\u001B[38;5;241m.\u001B[39merrors:\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:254\u001B[0m, in \u001B[0;36mCalibrator.calibrate\u001B[0;34m(self, dataset_gen)\u001B[0m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;129m@convert_phase\u001B[39m(Component\u001B[38;5;241m.\u001B[39mOPTIMIZE_TFLITE_MODEL, SubComponent\u001B[38;5;241m.\u001B[39mCALIBRATE)\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalibrate\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_gen):\n\u001B[1;32m    246\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calibrates the model with specified generator.\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \n\u001B[1;32m    248\u001B[0m \u001B[38;5;124;03m  Returns:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;124;03m    dataset_gen: A generator that generates calibration samples.\u001B[39;00m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 254\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_feed_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresize_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calibrator\u001B[38;5;241m.\u001B[39mCalibrate()\n",
      "File \u001B[0;32m~/miniforge3/envs/machine-learning/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:101\u001B[0m, in \u001B[0;36mCalibrator._feed_tensors\u001B[0;34m(self, dataset_gen, resize_input)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Feed tensors to the calibrator.\"\"\"\u001B[39;00m\n\u001B[1;32m     99\u001B[0m initialized \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 101\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m dataset_gen():\n\u001B[1;32m    102\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sample, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sample[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mdict\u001B[39m):\n",
      "Cell \u001B[0;32mIn[46], line 129\u001B[0m, in \u001B[0;36mTimeSeriesLSTM.convert_to_tflite.<locals>.representative_data_generator\u001B[0;34m()\u001B[0m\n\u001B[1;32m    126\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataframe_to_pred_data(representative_dataset)\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, sample \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(X):\n\u001B[0;32m--> 129\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[43msample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_columns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m {\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mfeature_columns[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m: sample}\n",
      "\u001B[0;31mValueError\u001B[0m: cannot reshape array of size 360 into shape (1,120,2)"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utils",
   "id": "ee35f19675a17710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:44:51.013020Z",
     "start_time": "2025-01-10T15:44:51.009939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_all_files(path):\n",
    "    try:\n",
    "        files = []\n",
    "\n",
    "        for f in os.listdir(path):\n",
    "            filepath = os.path.join(path, f)\n",
    "            if os.path.isfile(filepath):  # Prüft, ob es sich um eine Datei handelt\n",
    "                files.append(f)\n",
    "\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Das Verzeichnis '{path}' wurde nicht gefunden.\")\n",
    "        return []"
   ],
   "id": "5f712c5337735a19",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:57:59.571431Z",
     "start_time": "2025-01-10T15:47:21.455424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "ts_lstm.load_model(\"models/sleepPhaseAnalyserV1.keras\")\n",
    "\n",
    "files = list_all_files(\"data/4_squashed_format/\")\n",
    "\n",
    "for file in files:\n",
    "    print(\"Start Training with \" + file)\n",
    "    df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n",
    "    df_train = df_train.dropna()\n",
    "    \n",
    "    ts_lstm.train(dataframe=df_train[feature_columns + label_names])\n",
    "    ts_lstm.save_model(\"models/sleepPhaseAnalyserV1.keras\")\n",
    "print(\"Training completed!\")"
   ],
   "id": "bb3684e5744f60e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training with2024-08-23.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "704/704 [==============================] - 23s 29ms/step - loss: 0.2386 - accuracy: 0.7857\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 0.2385 - accuracy: 0.7857\n",
      "176/176 [==============================] - 3s 9ms/step - loss: 0.2405 - accuracy: 0.7806\n",
      "Loss: [0.2404816746711731, 0.7806004881858826]\n",
      "Model saved!\n",
      "Start Training with2024-09-05.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "763/763 [==============================] - 23s 30ms/step - loss: 0.1577 - accuracy: 0.8578\n",
      "Epoch 2/2\n",
      "763/763 [==============================] - 23s 30ms/step - loss: 0.1521 - accuracy: 0.8578\n",
      "191/191 [==============================] - 2s 9ms/step - loss: 0.1431 - accuracy: 0.8609\n",
      "Loss: [0.14311617612838745, 0.8608880639076233]\n",
      "Model saved!\n",
      "Start Training with2024-09-08.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "695/695 [==============================] - 21s 30ms/step - loss: 0.2236 - accuracy: 0.5177\n",
      "Epoch 2/2\n",
      "695/695 [==============================] - 21s 30ms/step - loss: 0.1868 - accuracy: 0.5203\n",
      "174/174 [==============================] - 2s 9ms/step - loss: 0.1655 - accuracy: 0.5379\n",
      "Loss: [0.16548559069633484, 0.5378801226615906]\n",
      "Model saved!\n",
      "Start Training with2024-08-22.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "544/544 [==============================] - 17s 30ms/step - loss: 0.2978 - accuracy: 0.3873\n",
      "Epoch 2/2\n",
      "544/544 [==============================] - 16s 30ms/step - loss: 0.2796 - accuracy: 0.3875\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2799 - accuracy: 0.3811\n",
      "Loss: [0.27985647320747375, 0.38114941120147705]\n",
      "Model saved!\n",
      "Start Training with2024-09-19.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "723/723 [==============================] - 24s 33ms/step - loss: 0.2514 - accuracy: 0.7644\n",
      "Epoch 2/2\n",
      "723/723 [==============================] - 24s 33ms/step - loss: 0.2459 - accuracy: 0.7652\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.2380 - accuracy: 0.7669\n",
      "Loss: [0.23804061114788055, 0.7669029831886292]\n",
      "Model saved!\n",
      "Start Training with2024-09-01.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "544/544 [==============================] - 16s 30ms/step - loss: 0.2108 - accuracy: 0.8643\n",
      "Epoch 2/2\n",
      "544/544 [==============================] - 19s 35ms/step - loss: 0.2039 - accuracy: 0.8633\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.2459 - accuracy: 0.8535\n",
      "Loss: [0.24593764543533325, 0.8534958362579346]\n",
      "Model saved!\n",
      "Start Training with2024-08-27.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "674/674 [==============================] - 20s 29ms/step - loss: 0.1689 - accuracy: 0.5985\n",
      "Epoch 2/2\n",
      "674/674 [==============================] - 20s 30ms/step - loss: 0.1552 - accuracy: 0.5961\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.1502 - accuracy: 0.5931\n",
      "Loss: [0.1501680165529251, 0.593135416507721]\n",
      "Model saved!\n",
      "Start Training with2024-08-29.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.1271 - accuracy: 0.8700\n",
      "Epoch 2/2\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.1214 - accuracy: 0.8704\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1304 - accuracy: 0.8721\n",
      "Loss: [0.13041536509990692, 0.8721362948417664]\n",
      "Model saved!\n",
      "Start Training with2024-08-21.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "742/742 [==============================] - 22s 30ms/step - loss: 0.2381 - accuracy: 0.8204\n",
      "Epoch 2/2\n",
      "742/742 [==============================] - 25s 34ms/step - loss: 0.2352 - accuracy: 0.8204\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.2266 - accuracy: 0.8339\n",
      "Loss: [0.22661004960536957, 0.8338668942451477]\n",
      "Model saved!\n",
      "Start Training with2024-09-03.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "647/647 [==============================] - 23s 35ms/step - loss: 0.2967 - accuracy: 0.8558\n",
      "Epoch 2/2\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.3124 - accuracy: 0.8558\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.3320 - accuracy: 0.8457\n",
      "Loss: [0.33202844858169556, 0.8456777930259705]\n",
      "Model saved!\n",
      "Start Training with2024-09-06.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "644/644 [==============================] - 19s 29ms/step - loss: 0.2676 - accuracy: 0.7725\n",
      "Epoch 2/2\n",
      "644/644 [==============================] - 20s 31ms/step - loss: 0.2647 - accuracy: 0.7725\n",
      "161/161 [==============================] - 2s 11ms/step - loss: 0.2615 - accuracy: 0.7789\n",
      "Loss: [0.2615232765674591, 0.7788573503494263]\n",
      "Model saved!\n",
      "Start Training with2024-08-30.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "747/747 [==============================] - 25s 34ms/step - loss: 0.2054 - accuracy: 0.8287\n",
      "Epoch 2/2\n",
      "747/747 [==============================] - 23s 31ms/step - loss: 0.2038 - accuracy: 0.8287\n",
      "187/187 [==============================] - 2s 9ms/step - loss: 0.1922 - accuracy: 0.8417\n",
      "Loss: [0.19219979643821716, 0.8417266011238098]\n",
      "Model saved!\n",
      "Start Training with2024-09-02.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97970/1478985355.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df_train = pd.read_json(\"data/4_squashed_format/\" + file, dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "693/693 [==============================] - 21s 30ms/step - loss: 0.3681 - accuracy: 0.7315\n",
      "Epoch 2/2\n",
      "693/693 [==============================] - 24s 35ms/step - loss: 0.3656 - accuracy: 0.7320\n",
      "174/174 [==============================] - 2s 11ms/step - loss: 0.3597 - accuracy: 0.7287\n",
      "Loss: [0.3596736788749695, 0.7286514043807983]\n",
      "Model saved!\n",
      "Training completed!\n"
     ]
    }
   ],
   "execution_count": 95
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
